{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAIN - Real & Artificial Intelligence for Neuroscience\n",
    "\n",
    "## Prepare positions\n",
    "\n",
    "Welcome!\n",
    "\n",
    "Here you'll find the initial steps to prepare your data for behavioral analysis.\n",
    "\n",
    "The position data obtained with pose estimation software (e.g., DeepLabCut or SLEAP) is usually stored in HDF files, with extension '.h5'.\n",
    "\n",
    "This notebook will:\n",
    "\n",
    "- Read HDF files of rodent tracking data.\n",
    "- Filter out low likelihood positions, interpolate and smoothen the data.\n",
    "- Prepare the position files to be analyzed.\n",
    "\n",
    "#### Requirements:\n",
    "A folder with:\n",
    "- HDF files containing the position of the mouse **bodyparts** and the **exploration targets** on the video.\n",
    "\n",
    "Or:\n",
    "- HDF files containing the position of the mouse **bodyparts**.\n",
    "- A separeate JSON file containing the ROIs of the exploration targets (see [0-Video_handling](0-Video_handling.ipynb)).\n",
    "\n",
    "If you dont have your position files with you, don't worry! You can demo the pipeline by working on the example data provided in the Rainstorm repository. It contains:\n",
    "- A **Novel Object Recognition** (NOR) task, with positions from each **mouse bodyparts**, analized using **DLC**. Locations of the **exploration targets** are added using points selected with the Draw ROIs tool in the [0-Video_handling](0-Video_handling.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Load the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import rainstorm.prepare_positions as rst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1. State your project path\n",
    "`base` : The path to the downloaded repository. If you are using a Windows path with backslashes, place an ‘r’ in front of the directory path to avoid an error (e.g. r'C:\\Users\\dhers\\Rainstorm').\n",
    "\n",
    "`folder_path` : The path to the folder containing the pose estimation files you want to use.\n",
    "\n",
    "`ROIs_path` : The path to the file with the Regions of Interest (ROIs). The ROIs.json file can be created using the `draw_rois` function on the [0-Video_handling](0-Video_handling.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your base path (e.g., to the Rainstorm repository)\n",
    "base = Path.cwd() # On my end, this is equivalent to Path(r'C:\\Users\\dhers\\Desktop\\Rainstorm').\n",
    "\n",
    "# Define the path to your experiment folder containing the pose estimation files\n",
    "folder_path = base / 'examples' / 'NOR' # To use the demo data, set folder_path to: base / 'examples' / 'NOR'\n",
    "\n",
    "# Define the path to your ROIs.json file (optional, will be used to scale distances from pixels to cm)\n",
    "ROIs_path = folder_path / 'ROIs.json' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2. Rename the files to end in '_position.h5'\n",
    "Since we use the data from different softwares, filenames end with something like '{Software_used + Network + name + date + snapshot}.h5'\n",
    "\n",
    "We start by editing the filenames. We are looking for the following:\n",
    "- Position files **must** end with the suffix '_position'.\n",
    "- (Optional) If the files belong to different trials of an experiment, they should contain the name of the trial in the filename.\n",
    "\n",
    "We can find an easy way to rename files below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first make a copy of the example position_files (so that we have a backup in case things go south)\n",
    "rst.backup_folder(folder_path, overwrite=False) # Set overwrite=True if you want to replace an existing backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the filenames as needed\n",
    "before =  'DLC_Resnet50_rainstormFeb17shuffle1_snapshot_200.h5' # 'DLC_Resnet50_rainstormFeb17shuffle1_snapshot_200.h5'for the NOR_example \n",
    "after = '_positions.h5'\n",
    "\n",
    "rst.rename_files(folder_path, before, after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3.  Create the params.yaml file\n",
    "\n",
    "The params.yaml file is a configuration file that contains all the parameters needed to run the analysis. It will be located in the experiment folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = rst.create_params(folder_path, ROIs_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Open the params.yaml file and modify (or not) the following parameters:\n",
    "\n",
    "The params.yaml file can be edited directly by opening the file, or...\n",
    "\n",
    "you can use the following function to open the **NEW `params editor GUI`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.open_params_editor(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Setup & Processing:\n",
    "\n",
    "`path` : Path to the experiment folder containing the pose estimation files\n",
    "\n",
    "`software` : Software used to generate the pose estimation files ('DLC' or 'SLEAP')\n",
    "\n",
    "`fps` : Video frames per second\n",
    "\n",
    "`filenames` : Pose estimation filenames\n",
    "\n",
    "`bodyparts` : Tracked bodyparts\n",
    "\n",
    "`prepare_positions` :\n",
    "- confidence: How many std_dev away from the mean the points likelihood can be without being erased (it is similar to asking 'how good is your tracking?')\n",
    "- median_filter: Number of frames to use for the median filter (it must be an odd number)\n",
    "- near_dist: Maximum distance (in cm) between two connected bodyparts. In c57 mice, I use half a tail length (around 4.5 cm).\n",
    "- far_dist: Maximum distance (in cm) between any two bodyparts. In c57 mice, I use whole body length (around 14 cm).\n",
    "- max_outlier_connections: If a bodypart has more than this number of long connections, it will be dropped from the frame.\n",
    "\n",
    "`targets` : Exploration targets (e.g., 'obj_1', 'obj_2')\n",
    "\n",
    "`trials` : If your experiment has multiple trials, list the trial names here (e.g., 'Hab', 'TR', 'TS')\n",
    "\n",
    "`target_roles` : State the roles targets can take on each trial (e.g., 'Hab': None, 'TR': ['Left', 'Right'], 'TS': ['Novel', 'Known'])\n",
    "\n",
    "#### Other parameters:\n",
    "\n",
    "`Geometric Analysis` : Will be used in the notebook [2b-Geometric_analysis](2b-Geometric_analysis.ipynb)\n",
    "\n",
    "`Automatic Analysis` : Will be used in the notebook [3a-Create_models](3a-Create_models.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 4. Open an example file and see what is inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_file_path = rst.choose_example_positions(params, look_for='TS', suffix='_positions.h5')\n",
    "df_raw = rst.open_h5_file(params, example_file_path, print_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, if the model is working properly, the mean likelihood of an existing point is close to 1.\n",
    "\n",
    "However, some points have lower mean likelihoods and higher standard deviations. This is because those points are harder to find (e.g. the nose tends to disappear during grooming).\n",
    "\n",
    "We will adjust our tolerance for each point, and erase only the positions that are below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 5. Add the position of stationary exploration targets\n",
    "As we talked about in the introduction, the position of the exploration targets can either be tracked using the same software we use to track our animals, or we can add them here.\n",
    "\n",
    "If our pose estimation model doesn't track the exploration targets, we can add them to the DataFrame using the following `add_targets` function.\n",
    "\n",
    "The `add_targets` function will add the points from `roi_data` in the params file **only** if they are also named in the `targets` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = rst.add_targets(params, df_raw, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 6. Now that we have our file, lets test our processing parameters in an example video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the smooth position data\n",
    "df_smooth = rst.filter_and_smooth_df(params, df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.plot_raw_vs_smooth(params, df_raw, df_smooth, bodypart='nose')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 7. Batch process all position files\n",
    "Now that we know what we are doing, we can apply all previous steps to all the files in our folder and store the results into csv files (lets face it, they are less scary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.process_position_files(params, targetless_trials=['Hab'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 8. Finally, we can organize the files into subfolders corresponding to different trials of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.filter_and_move_files(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "#### Our experiment folder now has subfolders according to the number of trials, each containing csv files with mice position.\n",
    "We can move on to the next notebook, [2b-Geometric_analysis](2b-Geometric_analysis.ipynb)\n",
    "\n",
    "---\n",
    "RAINSTORM - Created on Aug 27, 2023 - @author: Santiago D'hers\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainstorm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
