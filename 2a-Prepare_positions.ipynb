{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAIN - Real & Artificial Intelligence for Neuroscience\n",
    "\n",
    "## Prepare positions\n",
    "\n",
    "Welcome!\n",
    "\n",
    "This is the first oficial notebook of the Rainstorm project. Here you'll find the initial steps to prepare your data for analysis.\n",
    "\n",
    "The position data obtained with pose estimation software (e.g. DeepLabCut or SLEAP) is usually stored in HDF files, with extension '.h5'.\n",
    "\n",
    "This notebook will:\n",
    "\n",
    "- Read HDF files of rodent tracking data.\n",
    "- Filter out low likelihood positions, interpolate and smoothen the data.\n",
    "- Prepare the position files to be analyzed.\n",
    "\n",
    "#### Requirements:\n",
    "- A folder with:\n",
    "    - HDF files containing:\n",
    "        - The position of the mouse bodyparts on the video.\n",
    "        - The position of the **exploration targets** (Optional, since they can be added from the ROIs.json) .\n",
    "    - A JSON file containing the ROIs of the exploration targets (Optional, since they can be added from the HDF files).\n",
    "\n",
    "If you dont have your position files with you, don't worry! You can demo the pipeline by working on the example data provided in the Rainstorm repository. It contains:\n",
    "- A **Novel Object Recognition** (NOR) task, with positions from each **mouse bodyparts**, analized using **DLC**. Locations of the **exploration targets** are added using points selected with the `0-Video_handling` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Load the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rainstorm.prepare_positions as rst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1. State your project path\n",
    "`base` : The path to the downloaded repository. If you are using a Windows path with backslashes, place an ‘r’ in front of the directory path to avoid an error (e.g. r'C:\\Users\\dhers\\Rainstorm').\n",
    "\n",
    "`folder_path` : The path to the folder containing the pose estimation files you want to use.\n",
    "\n",
    "`ROIs_path` : The path to the file with the Regions of Interest (ROIs). The ROIs.json file can be created using the `draw_rois` function on the `0-Video_handling` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = r'C:\\Users\\dhers\\Desktop\\Rainstorm' # For the downloaded repository\n",
    "\n",
    "folder_path = os.path.join(base, r'docs\\examples\\NOR') # For the folder containing the pose estimation files you want to use\n",
    "ROIs_path = os.path.join(folder_path, 'ROIs.json') # For the ROIs.json file (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2. Rename the files to end in '_position.h5'\n",
    "To ease the analysis, we should start by editing the filenames. We are looking for the following:\n",
    "- Position files must end with the word '_position'.\n",
    "- Since we use the data from different softwares, filenames end with something like '{Software_used + Network + name + date + snapshot}.h5'.\n",
    "- (Optional) If the files belong to different trials of an experiment, they should contain the name of the trial in the filename.\n",
    "\n",
    "We can find an easy way to rename files below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first make a copy of the example position_files (so that we have a backup in case things go south)\n",
    "rst.backup_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the filenames as needed\n",
    "before =  'DLC_Resnet50_rainstormFeb17shuffle4_snapshot_200.h5' \n",
    "# 'DLC_Resnet50_rainstormFeb17shuffle4_snapshot_200.h5'for the NOR_example \n",
    "after = '_position.h5'\n",
    "\n",
    "rst.rename_files(folder_path, before, after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3.  Create the params.yaml file\n",
    "\n",
    "The params.yaml file is a configuration file that contains all the parameters needed to run the analysis. It will be located in the experiment folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = rst.create_params(folder_path, ROIs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Open the params.yaml file and modify the following parameters:\n",
    "\n",
    "`path` : Path to the experiment folder containing the pose estimation files\n",
    "\n",
    "`filenames` : Pose estimation filenames\n",
    "\n",
    "`software` : Software used to generate the pose estimation files ('DLC' or 'SLEAP')\n",
    "\n",
    "`fps` : Video frames per second\n",
    "\n",
    "`bodyparts` : Tracked bodyparts\n",
    "\n",
    "`targets` : Exploration targets\n",
    "\n",
    "`prepare_positions` : Parameters for processing positions:\n",
    "- confidence : How many std_dev away from the mean the points likelihood can be without being erased (it is similar to asking 'how good is your tracking?')\n",
    "- median_filter : Number of frames to use for the median filter (it must be an odd number)\n",
    "\n",
    "`geometric_analysis` : Parameters for geometric analysis:\n",
    "- roi_data : Loaded from ROIs.json\n",
    "  - frame_shape: Shape of the video frames ([width, height])\n",
    "  - scale: Scale of the video in px/cm\n",
    "  - areas: Defined ROIs (areas) in the frame\n",
    "  - points: Key points within the frame\n",
    "- distance : Maximum nose-target distance to consider exploration\n",
    "- orientation: Set up orientation analysis\n",
    "  - degree: Maximum head-target orientation angle to consider exploration (in degrees)\n",
    "  - front: Ending bodypart of the orientation line\n",
    "  - pivot: Starting bodypart of the orientation line\n",
    "- freezing_threshold : Movement threshold to consider freezing, computed as the mean std of all body parts over 1 second\n",
    "\n",
    "`automatic_analysis` : Parameters for automatic analysis:\n",
    "- model_path : Path to the model file\n",
    "- model_bodyparts : Bodyparts used to train the model\n",
    "- rescaling : Whether to rescale the data\n",
    "- reshaping : Whether to reshape the data (set to True for RNN)\n",
    "- RNN_width : Defines the shape of the RNN\n",
    "  - past : Number of past frames to include\n",
    "  - future : Number of future frames to include\n",
    "  - broad : Broaden the window by skipping some frames as we stray further from the present\n",
    "\n",
    "`seize_labels` : Parameters for the analysis of the experiment results:\n",
    "- groups : Experimental groups you want to compare\n",
    "- trials : If your experiment has multiple trials, list the trial names here\n",
    "- target_roles : Role/novelty of each target in the experiment\n",
    "- label_type : Type of labels used to measure exploration (geolabels, autolabels, labels, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 4. Open an example file and see what is inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_path = rst.choose_example_h5(params, look_for = 'TS') # You can use the 'look_for' variable to specify the file you want to use (e.g. 'TS_C1_A').\n",
    "\n",
    "# Open the example file:\n",
    "df_raw = rst.open_h5_file(params, example_path, print_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, if the model is working properly, the mean likelihood of an existing point is very close to 1.\n",
    "\n",
    "However, some points have lower mean likelihoods and higher standard deviations. This is because those points are harder to find (e.g. the nose tends to disappear during grooming).\n",
    "\n",
    "We will adjust our tolerance for each point, and erase only the positions that are below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 5. Add the position of stationary exploration targets\n",
    "As we talked about in the introduction, the position of the exploration targets can either be tracked using the same software we use to track our animals, or we can add them here.\n",
    "\n",
    "If our pose estimation model doesn't track the exploration targets, we can add them to the DataFrame using the following `add_targets` function.\n",
    "\n",
    "The `add_targets` function will add the points from `roi_data` in the params file **only** if they are also named in the `targets` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = rst.add_targets(params, df_raw, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 6. Now that we have our file, lets test our processing parameters in an example video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smooth = rst.filter_and_smooth_df(params, df_raw)\n",
    "\n",
    "rst.plot_raw_vs_smooth(params, df_raw, df_smooth, bodypart='nose')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 7. Batch process all position files\n",
    "Now that we know what we are doing, we can apply all previous steps to all the files in our folder and store the results into csv files (lets face it, they are less scary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process every file in the folder\n",
    "rst.process_position_files(params, targetless_trials=['Hab'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 8. Finally, we can organize the files into subfolders corresponding to different trials of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.filter_and_move_files(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "#### Our experiment folder now has subfolders according to the number of trials, each containing csv files with mice position.\n",
    "We can move on to the next notebook, `2b-Geometric_analysis.ipynb`\n",
    "\n",
    "---\n",
    "RAINSTORM - Created on Aug 27, 2023 - @author: Santiago D'hers\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainstorm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
