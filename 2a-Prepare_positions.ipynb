{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAIN - Real & Artificial Intelligence for Neuroscience\n",
    "\n",
    "## Prepare positions\n",
    "\n",
    "Welcome!\n",
    "\n",
    "Here you'll find the initial steps to prepare your data for behavioral analysis.\n",
    "\n",
    "The position data obtained with pose estimation software (e.g., DeepLabCut or SLEAP) is usually stored in HDF files, with extension '.h5'.\n",
    "\n",
    "This notebook will:\n",
    "\n",
    "- Read HDF files of rodent tracking data.\n",
    "- Filter out low likelihood positions, interpolate and smoothen the data.\n",
    "- Prepare the position files to be analyzed.\n",
    "\n",
    "#### Requirements:\n",
    "A folder with:\n",
    "- HDF files containing the position of the mouse **bodyparts** and the **exploration targets** on the video.\n",
    "\n",
    "Or:\n",
    "- HDF files containing the position of the mouse **bodyparts**.\n",
    "- A separeate JSON file containing the ROIs of the exploration targets (see [0-Video_handling](0-Video_handling.ipynb)).\n",
    "\n",
    "If you dont have your position files with you, don't worry! You can demo the pipeline by working on the example data provided in the Rainstorm repository. It contains:\n",
    "- A **Novel Object Recognition** (NOR) task, with positions from each **mouse bodyparts**, analized using **DLC**. Locations of the **exploration targets** are added using points selected with the Draw ROIs tool in the [0-Video_handling](0-Video_handling.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Load the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import rainstorm.prepare_positions as rst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1. State your project path\n",
    "`base` : The path to the downloaded repository. If you are using a Windows path with backslashes, place an ‘r’ in front of the directory path to avoid an error (e.g. r'C:\\Users\\dhers\\Rainstorm').\n",
    "\n",
    "`folder_path` : The path to the folder containing the pose estimation files you want to use.\n",
    "\n",
    "`ROIs_path` : The path to the file with the Regions of Interest (ROIs). The ROIs.json file can be created using the `draw_rois` function on the [0-Video_handling](0-Video_handling.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your base path (e.g., to the Rainstorm repository)\n",
    "base = Path.cwd() # On my end, this is equivalent to Path(r'C:\\Users\\dhers\\Desktop\\Rainstorm') \n",
    "\n",
    "# Define the path to your experiment folder containing the pose estimation files\n",
    "folder_path = base / 'examples' / 'NOR' # To use the demo data, set folder_path to: base / 'examples' / 'NOR'\n",
    "\n",
    "# Define the path to your ROIs.json file (optional)\n",
    "ROIs_path = folder_path / 'ROIs.json' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2. Rename the files to end in '_position.h5'\n",
    "Since we use the data from different softwares, filenames end with something like '{Software_used + Network + name + date + snapshot}.h5'\n",
    "\n",
    "We start by editing the filenames. We are looking for the following:\n",
    "- Position files **must** end with the suffix '_position'.\n",
    "- (Optional) If the files belong to different trials of an experiment, they should contain the name of the trial in the filename.\n",
    "\n",
    "We can find an easy way to rename files below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first make a copy of the example position_files (so that we have a backup in case things go south)\n",
    "rst.backup_folder(folder_path, overwrite=False) # Set overwrite=True if you want to replace an existing backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the filenames as needed\n",
    "before =  'DLC_Resnet50_rainstormFeb17shuffle4_snapshot_200.h5' # 'DLC_Resnet50_rainstormFeb17shuffle4_snapshot_200.h5'for the NOR_example \n",
    "after = '_positions.h5'\n",
    "\n",
    "rst.rename_files(folder_path, before, after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3.  Create the params.yaml file\n",
    "\n",
    "The params.yaml file is a configuration file that contains all the parameters needed to run the analysis. It will be located in the experiment folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = rst.create_params(folder_path, ROIs_path, targets_present=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Open the params.yaml file and modify the following parameters:\n",
    "\n",
    "`path` : Path to the experiment folder containing the pose estimation files\n",
    "\n",
    "`filenames` : Pose estimation filenames\n",
    "\n",
    "`software` : Software used to generate the pose estimation files ('DLC' or 'SLEAP')\n",
    "\n",
    "`fps` : Video frames per second\n",
    "\n",
    "`bodyparts` : Tracked bodyparts\n",
    "\n",
    "`targets` : Exploration targets\n",
    "\n",
    "`prepare_positions` : Parameters for processing positions:\n",
    "- confidence : How many std_dev away from the mean the points likelihood can be without being erased (it is similar to asking 'how good is your tracking?')\n",
    "- median_filter : Number of frames to use for the median filter (it must be an odd number)\n",
    "\n",
    "`geometric_analysis` : Parameters for geometric analysis:\n",
    "- roi_data : Loaded from ROIs.json\n",
    "  - frame_shape: Shape of the video frames ([width, height])\n",
    "  - scale: Scale of the video in px/cm\n",
    "  - areas: Defined ROIs (areas) in the frame\n",
    "  - points: Key points within the frame\n",
    "  - circles: Circular areas in the frame\n",
    "- target_exploration:\n",
    "  - distance : Maximum nose-target distance to consider exploration\n",
    "  - orientation: Set up orientation analysis\n",
    "    - degree: Maximum head-target orientation angle to consider exploration (in degrees)\n",
    "    - front: Ending bodypart of the orientation line\n",
    "    - pivot: Starting bodypart of the orientation line\n",
    "- freezing_threshold : Movement threshold to consider freezing, computed as the mean std of all body parts over 1 second\n",
    "\n",
    "`automatic_analysis` : Parameters for automatic analysis:\n",
    "- model_path : Path to the model file\n",
    "- model_bodyparts : Bodyparts used to train the model\n",
    "- rescaling : Whether to rescale the data\n",
    "- reshaping : Whether to reshape the data (set to True for RNN)\n",
    "- RNN_width : Defines the shape of the RNN\n",
    "  - past : Number of past frames to include\n",
    "  - future : Number of future frames to include\n",
    "  - broad : Broaden the window by skipping some frames as we stray further from the present\n",
    "\n",
    "`seize_labels` : Parameters for the analysis of the experiment results:\n",
    "- trials : If your experiment has multiple trials, list the trial names here\n",
    "- target_roles : Role/novelty of each target in the experiment\n",
    "- label_type : Type of labels used to measure exploration (geolabels, autolabels, labels, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 4. Open an example file and see what is inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_file_path = rst.choose_example_positions(params, look_for='TS_02', suffix='_positions.h5')\n",
    "df_raw = rst.open_h5_file(params, example_file_path, print_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, if the model is working properly, the mean likelihood of an existing point is close to 1.\n",
    "\n",
    "However, some points have lower mean likelihoods and higher standard deviations. This is because those points are harder to find (e.g. the nose tends to disappear during grooming).\n",
    "\n",
    "We will adjust our tolerance for each point, and erase only the positions that are below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 5. Add the position of stationary exploration targets\n",
    "As we talked about in the introduction, the position of the exploration targets can either be tracked using the same software we use to track our animals, or we can add them here.\n",
    "\n",
    "If our pose estimation model doesn't track the exploration targets, we can add them to the DataFrame using the following `add_targets` function.\n",
    "\n",
    "The `add_targets` function will add the points from `roi_data` in the params file **only** if they are also named in the `targets` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = rst.add_targets(params, df_raw, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 6. Now that we have our file, lets test our processing parameters in an example video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the smooth position data\n",
    "df_smooth = rst.filter_and_smooth_df(params, df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.plot_raw_vs_smooth(params, df_raw, df_smooth, bodypart='nose')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 7. Batch process all position files\n",
    "Now that we know what we are doing, we can apply all previous steps to all the files in our folder and store the results into csv files (lets face it, they are less scary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.process_position_files(params, targetless_trials=['Hab'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 8. Finally, we can organize the files into subfolders corresponding to different trials of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.filter_and_move_files(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "#### Our experiment folder now has subfolders according to the number of trials, each containing csv files with mice position.\n",
    "We can move on to the next notebook, [2b-Geometric_analysis](2b-Geometric_analysis.ipynb)\n",
    "\n",
    "---\n",
    "RAINSTORM - Created on Aug 27, 2023 - @author: Santiago D'hers\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainstorm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
