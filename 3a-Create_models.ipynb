{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAIN - Real & Artificial Intelligence for Neuroscience\n",
    "\n",
    "## Create models\n",
    "- This notebook will create and train Artificial Neural Networks to identify exploration using rodent and target position along with manually labeled data.\n",
    "\n",
    "#### Requirements:\n",
    "\n",
    "- A set of position files\n",
    "- Labeled data for those position files (to train the model)\n",
    "\n",
    "or\n",
    "\n",
    "- Access to the example file **colabels.csv**, where we can find:\n",
    "    - Position and labels for representative exploration events\n",
    "    - Manual labels from 5 viewers (so far)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Load the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import rainstorm.modeling as rst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1. State your models project path\n",
    "`base` : The path to the downloaded repository.\n",
    "\n",
    "`models_folder` : The path to the folder containing the files you'll use to create the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path.cwd()\n",
    "models_folder = base / 'examples' / 'models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Create the colabels file\n",
    "\n",
    "The Colabels file is a csv file that contains both mice positions, exploration target positions, and one or more sets of labels for the behavior you want to analyze.\n",
    "\n",
    "If you want to train the models using your own colabels file, you can create it using the create_colabels function below. \n",
    "\n",
    "All you need is:\n",
    "- A folder containing the positions of the mice\n",
    "- A folder for each labeler, containing the labels for the behavior you want to analyze\n",
    "- A list of the targets (stationary points) present on your videos\n",
    "\n",
    "\n",
    "```python\n",
    "path = r'path/to/colabels_folder' # The path to the directory containing the positions folder and labelers folders\n",
    "labelers = ['labeler_A', 'labeler_B', 'etc']\n",
    "targets = ['tgt_1', 'tgt_2', 'etc']\n",
    "\n",
    "rst.create_colabels(path, labelers, targets)\n",
    "```\n",
    "\n",
    "##### There is a Colabels file available in the models folder which contains positions and labels for mice on a novel object recognition task. If you want to analyze the demo data, train the models using that colabels file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2.  Create the modeling.yaml file\n",
    "\n",
    "The modeling.yaml file is a configuration file that contains all the parameters needed to create and train the models. It will be located in the models folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling = rst.create_modeling(models_folder, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It contains the following parameters:\n",
    "\n",
    "`path` : Path to the models folder\n",
    "\n",
    "`colabels` : The colabels file is used to store and organize positions and labels for model training\n",
    "- colabels_path: Path to the colabels folder\n",
    "- labelers: List of labelers on the colabels file (as found in the columns)\n",
    "- target: Name of the target on the colabels file\n",
    "\n",
    "`focus_distance`: Window of frames to consider around an exploration event\n",
    "\n",
    "`bodyparts`: List of bodyparts used to train the model\n",
    "\n",
    "`split`: Parameters for splitting the data into training, validation, and testing sets\n",
    "- validation: Percentage of the data to use for validation\n",
    "- test: Percentage of the data to use for testing\n",
    "\n",
    "`RNN`: Set up the Recurrent Neural Network\n",
    "- width: Defines the shape of the wide model\n",
    "  - past : Number of past frames to include\n",
    "  - future : Number of future frames to include\n",
    "  - broad : Broaden the window by skipping some frames as we stray further from the present\n",
    "- units: Number of neurons on each layer\n",
    "- batch_size: Number of training samples the model processes before updating its weights\n",
    "- dropout: Randomly turn off a fraction of neurons in the network\n",
    "- total_epochs: Each epoch is a complete pass through the entire training dataset\n",
    "- initial_lr: Initial learning rate\n",
    "- peak_lr: Peak learning rate\n",
    "- patience: Number of epochs to wait before early stopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3. Before training a model, we need to prepare our training data\n",
    "- First, we load the dataset from the colabels file and create one 'labels' column out of all the labelers.\n",
    "- Next (optional, but recommended) we can erase the rows of the dataset that are too far away from exploration events.\n",
    "- Finally, we split the dataset into training, testing and validation subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "dataset = rst.prepare_data(modeling)\n",
    "\n",
    "# Focus on the rows near exploratory behaviour\n",
    "dataset = rst.focus(modeling, dataset)\n",
    "\n",
    "# Split the data\n",
    "model_dict = rst.split_tr_ts_val(modeling, dataset)\n",
    "\n",
    "# Save the split\n",
    "rst.save_split(modeling, model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "If you later want to load a previous split, run:\n",
    "\n",
    "```python\n",
    "saved_split = models_folder / 'splits/split_{example_date}.h5' # Select the split you want to rescue\n",
    "model_dict = rst.load_split(saved_split)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We can see on the testing data that the exploratory events happen when the nose gets close to the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.plot_example_data(model_dict['X_ts'], model_dict['y_ts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 4. With the training data ready, we can use TensorFlow to design your very first model\n",
    "- It will look at the positions of one frame at a time, and try to decide if the mouse is exploring.\n",
    "- If the decision is correct the architecture will be reinforced, else it will be corrected according to the learning rate.\n",
    "- We will train it for some epochs (cycles through the whole dataset) and plot how the accuracy and loss evolve.\n",
    "- Also, we will be validating the training using the validation split, which contains frames that were not used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "import datetime\n",
    "time = datetime.datetime.now()\n",
    "\n",
    "# Build a simple neural network\n",
    "model_simple = tf.keras.Sequential([\n",
    "    \n",
    "    # Input layer\n",
    "    Input(shape=(model_dict['X_tr'].shape[1],)), \n",
    "\n",
    "    # Hidden layers\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    \n",
    "    # Output layer\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_simple.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001), \n",
    "                   loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_simple.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model\n",
    "Each ``epoch`` is a complete pass through the entire training dataset, while the ``batch_size`` is the number of training samples the model processes before updating its weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_simple = model_simple.fit(model_dict['X_tr'], model_dict['y_tr'],\n",
    "                                  epochs=10, batch_size=128,\n",
    "                                  validation_data=(model_dict['X_val'], model_dict['y_val']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.plot_history(history_simple, \"Simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate accuracy and precision of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_simple = model_simple.predict(model_dict['X_ts'])\n",
    "metrics_simple = rst.evaluate(y_pred_simple, model_dict['y_ts'], show_report = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And finally, save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'{time.date()}_simple'\n",
    "rst.save_model(modeling, model_simple, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 5. Now that we have a simple model trained, we can start building more complex models\n",
    "\n",
    "To make our artificial networks as real as possible, we can let them see a sequence of frames to decide if the mouse is exploring\n",
    "- Our build_RNN function will use Bidirectional LSTM layers that allow the model to take into account the temporal sequence of frames\n",
    "- It also implements early stopping and learning rate scheduler mechanisms that will prevent the model from overfitting\n",
    "\n",
    "We can control the RNN model by changing the following parameters on the modeling.yaml file:\n",
    "\n",
    "`units` : The number of neurons on each layer of the LSTM model\n",
    "\n",
    "`batch_size` : The number of training samples the model processes before updating its weights\n",
    "\n",
    "`lr` : The learning rate of the model\n",
    "\n",
    "`epochs` : The number of times the model will be trained on the entire training dataset\n",
    "\n",
    "`past` & `future` : If you use a LSTM model, you can set the window size by saying how many frames into the past and how many into the future you want to see.\n",
    "\n",
    "`broad` : Once you have your window size, we can broaden the window by skipping some frames as it strays further from the present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wide = rst.build_RNN(modeling, model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wide_name = f'{time.date()}_wide'\n",
    "history_wide = rst.train_RNN(modeling, model_wide, model_dict, model_wide_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.plot_history(history_wide, model_wide_name)\n",
    "rst.plot_lr_schedule(history_wide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate accuracy and precision of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_wide = model_wide.predict(model_dict['X_ts_wide'])\n",
    "metrics_wide = rst.evaluate(y_pred_wide, model_dict['y_ts'], show_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the wide model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.save_model(modeling, model_wide, model_wide_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 6. Finally, compare the trained models\n",
    "\n",
    "- Since we trained using the training dataset, and validated using the validation dataset... we test each model using the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model results\n",
    "print(\"Evaluate model vs testing data\")\n",
    "print(f\"{metrics_simple} -> simple\")\n",
    "print(f\"{metrics_wide} -> wide\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "#### Our trained models are stored safely in our repository, with today's date.\n",
    "We can:\n",
    "- Continue on this notebook and evaluate the trained models.\n",
    "- Skip the evaluation and go use the models on our data in [3b-Automatic_analysis](3b-Automatic_analysis.ipynb).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models\n",
    "\n",
    "I see you've decided to continue on this notebook! You wont regret it.\n",
    "\n",
    "One may think that the evaluation we did on the testing set is enough, and in many cases it is. However, for our purpose of finding a model that resembles the labeling of an expert, It's better to compare the performance of the model against all the manually labeled data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dict = rst.build_evaluation_dict(modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 7. Calculate a good reference labeler\n",
    "Since we want to compare the models and the labelers, we need to create a reference labeler.\n",
    "\n",
    "This reference could be the mean of all the labelers, but then the labelers would have an unfair advantage.\n",
    "\n",
    "To avoid this, we choose to simultaneously create a chimera labeler and a leave-one-out-mean:\n",
    "- The chimera is created by randomly selecting a labeler on each row of the data.\n",
    "- The leave-one-out-mean is created by averaging the remaining labelers.\n",
    "\n",
    "This way, we can compare the chimera to the leave-one-out-mean knowing that they are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chimera_dict = rst.create_chimera_and_loo_mean(evaluation_dict['manual_labels'], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 8. Load the models & use them to label exploration on all the available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the models you want to evaluate\n",
    "model_paths = {\n",
    "    'example_simple': models_folder / 'trained_models/example_simple.keras',\n",
    "    'example_wide': models_folder / 'trained_models/example_wide.keras',\n",
    "    f'{time.date()}_simple': models_folder / f'trained_models/{time.date()}_simple.keras',\n",
    "    f'{time.date()}_wide': models_folder / f'trained_models/{time.date()}_wide.keras',\n",
    "    # Add more models as needed...\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = rst.build_and_run_models(modeling, model_paths, evaluation_dict['position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dict.update(chimera_dict)\n",
    "evaluation_dict.update(models_dict)\n",
    "evaluation_dict = {k: v for k, v in evaluation_dict.items() if k not in {'position', 'manual_labels'}}\n",
    "print(evaluation_dict.keys())  # Check the keys to confirm the additions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 9. With all the labels organized, we can evaulate the performance of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, pred in evaluation_dict.items():\n",
    "    metrics = rst.evaluate(pred, evaluation_dict['loo_mean'])\n",
    "    print(f\"{metrics} -> {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the similarity between labelers using a cosine similarity plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.plot_cosine_sim(evaluation_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, run a PCA (Principal Components Analysis) to see how much each labeler resembles eachother and the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.plot_PCA(evaluation_dict, make_discrete=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we can see both the models and the labelers performance on an example video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_folder_path = base / r'examples\\colabeled_video'\n",
    "\n",
    "labelers_example = {\n",
    "    \"labeler_A\": \"Example_labeler_A.csv\",\n",
    "    \"labeler_B\": \"Example_labeler_B.csv\",\n",
    "    \"labeler_C\": \"Example_labeler_C.csv\",\n",
    "    \"labeler_D\": \"Example_labeler_D.csv\",\n",
    "    \"labeler_E\": \"Example_labeler_E.csv\"\n",
    "}\n",
    "\n",
    "rst.plot_performance_on_video(example_folder_path, model_paths, labelers_example, fps = 25, \n",
    "                              bodyparts = ['nose', 'left_ear', 'right_ear', 'head', 'neck', 'body'], \n",
    "                              targets = ['obj_1', 'obj_2'], plot_tgt = \"obj_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "#### Once we get to this point, we should have selected our favorite model.\n",
    "We can move on to the next notebook, [3b-Automatic_analysis](3b-Automatic_analysis.ipynb), and use the chosen model to label our position files.\n",
    "\n",
    "---\n",
    "RAINSTORM - Created on Dec 12, 2023 - @author: Santiago D'hers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainstorm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
