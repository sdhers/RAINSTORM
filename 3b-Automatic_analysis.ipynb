{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAIN - Real & Artificial Intelligence for Neuroscience\n",
    "\n",
    "## Automatic analysis\n",
    "- Use a trained model from [3a-Create_models](3a-Create_models.ipynb) to label the position files.\n",
    "\n",
    "#### Requirements:\n",
    "- The position.csv files.\n",
    "- A trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Load the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import rainstorm.modeling as rst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1. State your project path\n",
    "You need to define the path to the same folder used in [2a-Prepare_positions](2a-Prepare_positions.ipynb), and the path to the parameters file (which contains the parameters for automatic analysis).\n",
    "\n",
    "On the params.yaml file, **change the model_path for the path to the trained model** created in [3a-Create_models](3a-Create_models.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path.cwd()\n",
    "folder_path = base / 'examples' / 'NOR'\n",
    "params = folder_path / 'params.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Open the params.yaml file and make sure the parameters match the model you want to use for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.open_params_editor(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic Analysis\n",
    "\n",
    "- `models_path` : Path to the models folder containing trained neural networks.\n",
    "- `analyze_with` : **Model file to use for analysis** (.keras format).\n",
    "- `model_bodyparts` : Bodyparts used to train the model.\n",
    "\n",
    "RNN Configuration\n",
    "\n",
    "- `rescaling` : Whether to rescale the data  \n",
    "- `reshaping` : Whether to reshape the data (set to True for RNN)  \n",
    "- `RNN_width` : Defines the shape of the RNN  \n",
    "  - `past` : Number of past frames to include  \n",
    "  - `future` : Number of future frames to include  \n",
    "  - `broad` : Broaden the window by skipping some frames as we stray further from the present  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2. Run the model on all the data selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.create_autolabels(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "#### A new csv file was created for each video, containing the autolabels.\n",
    "\n",
    "We can:\n",
    "- Continue on this notebook and compare the results of the manual, geometric & automatic methods on our example files\n",
    "- Skip the methods comparison, go straight to [4-Seize_labels](4-Seize_labels.ipynb) and use the autolabels to plot the results of the experiment\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare labels\n",
    "Lets do a quick recap of what we have done so far...\n",
    "\n",
    "- Recorded mice exploring objects.\n",
    "- Aligned the videos using the Rainstorm Video Aligner, and...\n",
    "- Drawn ROIs and targets present, and set a scaling factor using the drawing tool on [0-Video_handling](0-Video_handling.ipynb).\n",
    "- Analyzed the videos using pose estimation software (like DeepLabCut).\n",
    "- **Manually labeled** the positions of the mice using the Rainstorm Behavioral Tagger on [1-Behavioral_labeler](1-Behavioral_labeler.ipynb).\n",
    "- Processed the positions on [2a-Prepare_positions](2a-Prepare_positions.ipynb).\n",
    "- **Geometrically labeled** the positions on [2b-Geometric_analysis](2b-Geometric_analysis.ipynb).\n",
    "- Trained some Artificial Neural Networks on [3a-Create_models](3a-Create_models.ipynb).\n",
    "- **Automatically labeled** the positions on [3b-Automatic_analysis](3b-Automatic_analysis.ipynb).\n",
    "\n",
    "And here we are! Now, we can compare between manual labels, geolabels & autolabels.\n",
    "\n",
    "I have labeled the example videos myself using the RAINSTORM labeler tool, and left those manual labels available on the example folder.\n",
    "\n",
    "If you want to see the original videos and label them to compare yourself with the machine, you can find the videos on 'examples/NOR/TS_videos'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3. Polar graph \n",
    "A great way of visualizing the distance and angle of approach to an object is to use a polar graph. The distance is represented in the radius of the circle, and the circumference represents the angle of the vector from the head to the nose.\n",
    "\n",
    "Since the graph is symmetrical, we will use the left side to color the automatic labels in red, and the right side to color the manual labels in blue. The graph will also show the geometric labels as all the points that fit inside the dashed line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can open a single example file and it's labels\n",
    "positions, manual_labels, geolabels, autolabels = rst.prepare_label_comparison(params, include_all=False)\n",
    "\n",
    "rst.polar_graph(params, positions, autolabels, manual_labels, target_name='obj_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can load all the data from all the available files and plot the polar graph again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time we set 'include_all' to True\n",
    "all_positions, all_manual_labels, all_geolabels, all_autolabels = rst.prepare_label_comparison(params, include_all=True)\n",
    "\n",
    "# This time it might take a few seconds\n",
    "rst.polar_graph(params, all_positions, all_autolabels, all_manual_labels, target_name='obj_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 4. Evaluate accuracy of predictions\n",
    "Finally, we can evaluate the accuracy of the predictions by comparing the geometric and automatic labels to the manual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For geolabels\n",
    "rst.accuracy_scores(all_manual_labels, all_geolabels, targets=['obj_1','obj_2'], method_name=\"geometric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For autolabels\n",
    "rst.accuracy_scores(all_manual_labels, all_autolabels, targets=['obj_1','obj_2'], method_name=\"automatic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "#### Both geometric and automatic methods are flawed when compared to human labeling.\n",
    "#### However, as the only human responsible for the example manual labels provided, let me tell you that I am flawed too.\n",
    "#### Probably if more people labeled these videos and we compare against the average labels, we would have less error.\n",
    "\n",
    "We can:\n",
    "- Go to [4-Seize_labels](4-Seize_labels.ipynb) and use the labels to plot the results of the experiment.\n",
    "\n",
    "---\n",
    "RAINSTORM - Created on Apr 18, 2024 - @author: Santiago D'hers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainstorm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
