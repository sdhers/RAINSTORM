{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on Thu Apr 18 05:43:21 2024\n",
    "\n",
    "@author: Santiago D'hers\n",
    "\n",
    "Use:\n",
    "\n",
    "- This script will create autolabels analyzing position files\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- The position.csv files processed by 1-Manage_H5.py\n",
    "- The desired model trained with 3a-Create_Models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import joblib\n",
    "from keras.models import load_model\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the variables before starting\n",
    "desktop = 'C:/Users/dhers/Desktop'\n",
    "STORM_folder = os.path.join(desktop, 'STORM/models')\n",
    "\n",
    "# State your path:\n",
    "path = r'C:\\Users\\dhers\\OneDrive - UBA\\workshop'\n",
    "experiment = r'TORM'\n",
    "\n",
    "before, after = 2, 2\n",
    "frames = before + after + 1\n",
    "\n",
    "all_position = glob(os.path.join(path, experiment,\"T*/position/*position.csv\"))\n",
    "\n",
    "today = datetime.datetime.now()\n",
    "# use_model_date = today.date()\n",
    "use_model_date = '2024-10-13'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model from file\n",
    "\n",
    "loaded_model = load_model(os.path.join(STORM_folder, f'simple/model_simple_{use_model_date}.keras'))\n",
    "# loaded_model = load_model(os.path.join(STORM_folder, f'wide/model_wide_{use_model_date}.keras'))\n",
    "# loaded_model = joblib.load(os.path.join(STORM_folder, f'RF/model_RF_{use_model_date}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter(df, window_size = 3):\n",
    "    if window_size % 2 == 0:\n",
    "        raise ValueError(\"Window size must be odd\")\n",
    "    \n",
    "    # Apply the median filter\n",
    "    filtered_df = df.apply(lambda x: x.rolling(window=window_size, center=True).median())\n",
    "    \n",
    "    # Fill NaN values with the original values\n",
    "    filtered_df = filtered_df.combine_first(df)\n",
    "    \n",
    "    # Count the number of changed values\n",
    "    changed_values_count = (df != filtered_df).sum().sum()\n",
    "    \n",
    "    # Print the count of changed values\n",
    "    print(f\"Number of values changed by the filter: {changed_values_count}\")\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "def sigmoid(x, k=20):\n",
    "    return 1 / (1 + np.exp(-k * x+(k/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(df, obj_cols = 4, body_cols = 16, labels = True):\n",
    "    \n",
    "    # First for the object on the left\n",
    "    # Select columns 5 to 16 (bodyparts)\n",
    "    left_df = df.iloc[:, obj_cols:body_cols].copy()\n",
    "    \n",
    "    # Calculate the offsets for x and y coordinates for each row\n",
    "    x_left = df.iloc[:, 0].copy()  # Assuming x-coordinate is in the first column\n",
    "    y_left = df.iloc[:, 1].copy()  # Assuming y-coordinate is in the second column\n",
    "\n",
    "    # Subtract the offsets from all values in the appropriate columns\n",
    "    for col in range(0, left_df.shape[1]):\n",
    "        if col % 2 == 0:  # Even columns\n",
    "            left_df.iloc[:, col] -= x_left\n",
    "        else:  # Odd columns\n",
    "            left_df.iloc[:, col] -= y_left\n",
    "    \n",
    "    # Now for the object on the right\n",
    "    # Select columns 5 to 16 (bodyparts)\n",
    "    right_df = df.iloc[:, obj_cols:body_cols].copy()\n",
    "    \n",
    "    # Calculate the offsets for x and y coordinates for each row\n",
    "    x_right = df.iloc[:, 2].copy()  # Assuming x-coordinate is in the first column\n",
    "    y_right = df.iloc[:, 3].copy()  # Assuming y-coordinate is in the second column\n",
    "\n",
    "    # Subtract the offsets from all values in the appropriate columns\n",
    "    for col in range(0, right_df.shape[1]):\n",
    "        if col % 2 == 0:  # Even columns\n",
    "            right_df.iloc[:, col] -= x_right\n",
    "        else:  # Odd columns\n",
    "            right_df.iloc[:, col] -= y_right\n",
    "    \n",
    "    if labels:\n",
    "        left_df['Labels'] = df.iloc[:, -2].copy()\n",
    "        right_df['Labels'] = df.iloc[:, -1].copy()\n",
    "    \n",
    "    final_df = pd.concat([left_df, right_df], ignore_index=True)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(data, labels, back, forward):\n",
    "        \n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = data.to_numpy()\n",
    "    reshaped_data = []\n",
    "    \n",
    "    if labels is not False:\n",
    "        if isinstance(labels, pd.DataFrame):\n",
    "            labels = labels.to_numpy()\n",
    "        reshaped_labels = []\n",
    "        \n",
    "    for i in range(0, back):\n",
    "        reshaped_data.append(data[: 1 + back + forward])\n",
    "        if labels is not False:\n",
    "            reshaped_labels.append(labels[0])\n",
    "            \n",
    "    for i in range(back, len(data) - forward):\n",
    "        reshaped_data.append(data[i - back : 1 + i + forward])\n",
    "        if labels is not False:\n",
    "            reshaped_labels.append(labels[i])\n",
    "    \n",
    "    for i in range(len(data) - forward, len(data)):\n",
    "        reshaped_data.append(data[-(1 + back + forward):])\n",
    "        if labels is not False:\n",
    "            reshaped_labels.append(labels[i])\n",
    "    \n",
    "    reshaped_data_tf = tf.convert_to_tensor(reshaped_data, dtype=tf.float64)\n",
    "    \n",
    "    if labels is not False:\n",
    "        reshaped_labels_tf = tf.convert_to_tensor(reshaped_labels, dtype=tf.float64)\n",
    "    \n",
    "        return reshaped_data_tf, reshaped_labels_tf\n",
    "    \n",
    "    return reshaped_data_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_model(position, model, rescaling = True, reshaping = False):\n",
    "    \n",
    "    if rescaling:\n",
    "        df = rescale(position, labels = False)\n",
    "    \n",
    "    if reshaping:\n",
    "        df = reshape(df, False, before, after)\n",
    "    \n",
    "    pred = model.predict(df)\n",
    "    \n",
    "    pred = pred.flatten()\n",
    "    \n",
    "    # Determine the midpoint\n",
    "    midpoint = len(pred) // 2\n",
    "    \n",
    "    # Split the array into two halves\n",
    "    left = pred[:midpoint]\n",
    "    right = pred[midpoint:]\n",
    "    \n",
    "    # Create a new DataFrame with the two halves as separate columns\n",
    "    labels = pd.DataFrame({\n",
    "        'Left': left,\n",
    "        'Right': right\n",
    "    })\n",
    "    \n",
    "    # labels = median_filter(labels.round(2))\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autolabels(files, chosen_model, rescaling = True, reshaping = False):\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        # Determine the output file path\n",
    "        input_dir, input_filename = os.path.split(file)\n",
    "        parent_dir = os.path.dirname(input_dir)\n",
    "        \n",
    "        # Read the file\n",
    "        position = pd.read_csv(file)\n",
    "        \n",
    "        # Remove the rows where the mouse is still not in the video, excluding the first 4 columns (the object)\n",
    "        original_rows = position.shape[0]\n",
    "        position.dropna(subset = position.columns[4:], inplace=True)\n",
    "        position.reset_index(drop=True, inplace=True)\n",
    "        rows_removed = original_rows - position.shape[0]\n",
    "        \n",
    "        position = position.drop(['tail_1_y', 'tail_1_x','tail_2_x', 'tail_2_y', 'tail_3_x', 'tail_3_y'], axis=1)\n",
    "    \n",
    "        # lets analyze it!\n",
    "        autolabels = use_model(position, chosen_model, rescaling, reshaping)\n",
    "        \n",
    "        # Add rows filled with zeros at the beginning of autolabels\n",
    "        zeros_rows = pd.DataFrame(np.nan, index=np.arange(rows_removed), columns=autolabels.columns)\n",
    "        autolabels = pd.concat([zeros_rows, autolabels]).reset_index(drop=True)\n",
    "        \n",
    "        # Set column names and add a new column \"Frame\" with row numbers\n",
    "        autolabels.insert(0, \"Frame\", autolabels.index + 1)\n",
    "    \n",
    "        # Create a filename for the output CSV file\n",
    "        output_filename = input_filename.replace('_position.csv', '_autolabels.csv')\n",
    "        output_folder = os.path.join(parent_dir + '/autolabels')\n",
    "        \n",
    "        # Make the output folder (if it does not exist)\n",
    "        os.makedirs(output_folder, exist_ok = True)\n",
    "        \n",
    "        # Save the DataFrame to a CSV file\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        autolabels.to_csv(output_path, index=False)\n",
    "    \n",
    "        print(f\"Processed {input_filename} and saved results to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_autolabels(all_position, loaded_model, rescaling = True, reshaping = False) # Lets analyze!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "storm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
