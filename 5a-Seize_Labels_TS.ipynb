{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on Thu Oct 26 10:28:08 2023\n",
    "\n",
    "@author: Santiago D'hers\n",
    "\n",
    "Use:\n",
    "\n",
    "- This script will help us visualize the results of labeled videos\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- The position.csv files processed by 1-Manage_H5.py\n",
    "\n",
    "- Geolabels, autolabels or manual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point:\n",
    "    def __init__(self, df, table):\n",
    "\n",
    "        x = df[table + '_x']\n",
    "        y = df[table + '_y']\n",
    "\n",
    "        self.positions = np.dstack((x, y))[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def dist(p1, p2):\n",
    "        return np.linalg.norm(p1.positions - p2.positions, axis=1)\n",
    "\n",
    "class Vector:\n",
    "    def __init__(self, p1, p2, normalize=True):\n",
    "\n",
    "        self.positions = p2.positions - p1.positions\n",
    "\n",
    "        self.norm = np.linalg.norm(self.positions, axis=1)\n",
    "\n",
    "        if normalize:\n",
    "            self.positions = self.positions / np.repeat(np.expand_dims(self.norm,axis=1), 2, axis=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def angle(v1, v2):\n",
    "        \n",
    "        length = len(v1.positions)\n",
    "        angle = np.zeros(length)\n",
    "\n",
    "        for i in range(length):\n",
    "            angle[i] = np.rad2deg(np.arccos(np.dot(v1.positions[i], v2.positions[i])))\n",
    "\n",
    "        return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State your path:\n",
    "path = r'C:\\Users\\dhers\\OneDrive - UBA\\workshop'\n",
    "experiment = r'b2-mix'\n",
    "\n",
    "# Since we are going to analyze only one session of the experiment, we need to access its folder (eg: TS)\n",
    "TS_folder = os.path.join(path, experiment, 'TS')\n",
    "\n",
    "# State which labels you want to use\n",
    "label_type = 'geolabels'\n",
    "objects = ['obj_1', 'obj_2']\n",
    "\n",
    "t_lim = None # seconds\n",
    "video_fps = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reference(folder_path, label_type, obj_pair):\n",
    "    \n",
    "    reference_path = os.path.join(folder_path, 'reference.csv')\n",
    "    \n",
    "    labels_path = os.path.join(folder_path, label_type)\n",
    "    \n",
    "    # Check if Reference.csv already exists\n",
    "    if os.path.exists(reference_path):\n",
    "        print(\"Reference file already exists\")\n",
    "        return reference_path\n",
    "    \n",
    "    # Get a list of all CSV files in the labels folder\n",
    "    labels_files = [file for file in os.listdir(labels_path) if file.endswith(f'_{label_type}.csv')]\n",
    "    labels_files = sorted(labels_files)\n",
    "\n",
    "    # Create a new CSV file with a header 'Videos'\n",
    "    with open(reference_path, 'w', newline='') as output_file:\n",
    "        csv_writer = csv.writer(output_file)\n",
    "        col_list = ['Video','Group'] + obj_pair\n",
    "        csv_writer.writerow(col_list)\n",
    "\n",
    "        # Write each position file name in the 'Videos' column\n",
    "        for file in labels_files:\n",
    "            # Remove \"_position.csv\" from the file name\n",
    "            clean_name = file.replace(f'_{label_type}.csv', '')\n",
    "            csv_writer.writerow([clean_name])\n",
    "\n",
    "    print(f\"CSV file '{reference_path}' created successfully with the list of video files.\")\n",
    "    \n",
    "    return reference_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference file already exists\n"
     ]
    }
   ],
   "source": [
    "# Lets create the reference.csv file\n",
    "reference_path = create_reference(TS_folder, label_type, objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STOP! Go to the Reference file and complete the 'Group','Left' and 'Right' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_labels(reference_path, label_type, obj_pair):\n",
    "    \n",
    "    parent_dir = os.path.dirname(reference_path)\n",
    "    reference = pd.read_csv(reference_path)\n",
    "    \n",
    "    # Create a subfolder named \"final_{label_type}\"\n",
    "    renamed_path = os.path.join(parent_dir, f'final_{label_type}')\n",
    "\n",
    "    # Check if it exists\n",
    "    if os.path.exists(renamed_path):\n",
    "        print(f'final_{label_type} already exists')\n",
    "    \n",
    "    os.makedirs(renamed_path, exist_ok = True)\n",
    "    \n",
    "    group_list = []\n",
    "    \n",
    "    # Iterate through each row in the table\n",
    "    for index, row in reference.iterrows():\n",
    "        \n",
    "        video_name = row['Video']\n",
    "        group_name = row['Group']\n",
    "        Left = row[obj_pair[0]]\n",
    "        Right = row[obj_pair[1]]\n",
    "\n",
    "        # Create the old and new file paths\n",
    "        old_file_path = parent_dir + f'/{label_type}' + f'/{video_name}_{label_type}.csv'\n",
    "        new_video_name = f'{group_name}_{video_name}_final_{label_type}.csv'\n",
    "        new_file_path = os.path.join(renamed_path, f'{new_video_name}')\n",
    "    \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(old_file_path)\n",
    "    \n",
    "        # Rename the columns based on the 'Left' and 'Right' values\n",
    "        df = df.rename(columns={obj_pair[0]: Left, obj_pair[1]: Right})\n",
    "        \n",
    "        # We order the columns alphabetically\n",
    "        to_sort = list(df.columns[1:])\n",
    "        \n",
    "        if Left == \"Novel\" or Right == \"Novel\":\n",
    "            df = df[['Frame'] + sorted(to_sort, reverse=True)]\n",
    "        else:\n",
    "            df = df[['Frame'] + sorted(to_sort)]\n",
    "    \n",
    "        # Fill NaN values with zeros\n",
    "        df = df.fillna(0)\n",
    "    \n",
    "        # Save the modified DataFrame to a new CSV file\n",
    "        df.to_csv(new_file_path, index=False)\n",
    "    \n",
    "        # Optionally, you can remove the old file if needed\n",
    "        # os.remove(old_file_path)\n",
    "        \n",
    "        group_list.append(group_name)\n",
    "    \n",
    "        print(f'Renamed and saved: {new_file_path}')\n",
    "    \n",
    "    group_list = sorted(list(set(group_list)))\n",
    "        \n",
    "    return renamed_path, group_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth WT_2024-04_TORM-Tg-2m_TS_C1_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth WT_2024-04_TORM-Tg-2m_TS_C1_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth WT_2024-04_TORM-Tg-2m_TS_C1_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth 3xTg_2024-04_TORM-Tg-2m_TS_C1_B_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth 3xTg_2024-04_TORM-Tg-2m_TS_C2_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth 3xTg_2024-04_TORM-Tg-2m_TS_C2_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth 3xTg_2024-04_TORM-Tg-2m_TS_C3_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth 3xTg_2024-04_TORM-Tg-2m_TS_C3_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth 3xTg_2024-04_TORM-Tg-2m_TS_C3_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth WT_2024-04_TORM-Tg-2m_TS_C4_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth WT_2024-04_TORM-Tg-2m_TS_C4_B_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth WT_2024-04_TORM-Tg-2m_TS_C5_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth WT_2024-04_TORM-Tg-2m_TS_C5_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth WT_2024-04_TORM-Tg-2m_TS_C5_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth WT_2024-04_TORM-Tg-2m_TS_C5_B_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth 3xTg_2024-04_TORM-Tg-2m_TS_C6_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth 3xTg_2024-04_TORM-Tg-2m_TS_C6_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\2 mth 3xTg_2024-04_TORM-Tg-2m_TS_C6_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth WT_2024-05_TORM-Tg-3m_TS_C1_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth WT_2024-05_TORM-Tg-3m_TS_C1_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth WT_2024-05_TORM-Tg-3m_TS_C1_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth 3xTg_2024-05_TORM-Tg-3m_TS_C1_B_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth 3xTg_2024-05_TORM-Tg-3m_TS_C2_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth 3xTg_2024-05_TORM-Tg-3m_TS_C2_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth 3xTg_2024-05_TORM-Tg-3m_TS_C3_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth 3xTg_2024-05_TORM-Tg-3m_TS_C3_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth 3xTg_2024-05_TORM-Tg-3m_TS_C3_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth WT_2024-05_TORM-Tg-3m_TS_C4_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth WT_2024-05_TORM-Tg-3m_TS_C4_B_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth WT_2024-05_TORM-Tg-3m_TS_C5_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth WT_2024-05_TORM-Tg-3m_TS_C5_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth WT_2024-05_TORM-Tg-3m_TS_C5_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth WT_2024-05_TORM-Tg-3m_TS_C5_B_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth 3xTg_2024-05_TORM-Tg-3m_TS_C6_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth 3xTg_2024-05_TORM-Tg-3m_TS_C6_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\3 mth 3xTg_2024-05_TORM-Tg-3m_TS_C6_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth WT_2024-08_TORM-Tg-6m_TS_C1_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth WT_2024-08_TORM-Tg-6m_TS_C1_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth WT_2024-08_TORM-Tg-6m_TS_C1_C_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth 3xTg_2024-08_TORM-Tg-6m_TS_C2_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth 3xTg_2024-08_TORM-Tg-6m_TS_C2_B_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth 3xTg_2024-08_TORM-Tg-6m_TS_C2_C_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth 3xTg_2024-08_TORM-Tg-6m_TS_C3_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth 3xTg_2024-08_TORM-Tg-6m_TS_C3_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth 3xTg_2024-08_TORM-Tg-6m_TS_C3_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth WT_2024-08_TORM-Tg-6m_TS_C4_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth WT_2024-08_TORM-Tg-6m_TS_C4_B_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth WT_2024-08_TORM-Tg-6m_TS_C5_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth WT_2024-08_TORM-Tg-6m_TS_C5_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth WT_2024-08_TORM-Tg-6m_TS_C5_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth WT_2024-08_TORM-Tg-6m_TS_C5_B_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth 3xTg_2024-08_TORM-Tg-6m_TS_C6_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth 3xTg_2024-08_TORM-Tg-6m_TS_C6_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\6 mth 3xTg_2024-08_TORM-Tg-6m_TS_C6_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth WT_2024-09_NOR-Tg-6m_TS_C1_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth WT_2024-09_NOR-Tg-6m_TS_C1_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth WT_2024-09_NOR-Tg-6m_TS_C1_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth 3xTg_2024-09_NOR-Tg-6m_TS_C2_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth 3xTg_2024-09_NOR-Tg-6m_TS_C2_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth 3xTg_2024-09_NOR-Tg-6m_TS_C2_B_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth 3xTg_2024-09_NOR-Tg-6m_TS_C3_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth 3xTg_2024-09_NOR-Tg-6m_TS_C3_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth 3xTg_2024-09_NOR-Tg-6m_TS_C3_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth WT_2024-09_NOR-Tg-6m_TS_C4_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth WT_2024-09_NOR-Tg-6m_TS_C4_B_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth WT_2024-09_NOR-Tg-6m_TS_C5_A_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth WT_2024-09_NOR-Tg-6m_TS_C5_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth WT_2024-09_NOR-Tg-6m_TS_C5_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth WT_2024-09_NOR-Tg-6m_TS_C5_B_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth 3xTg_2024-09_NOR-Tg-6m_TS_C6_A_R_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth 3xTg_2024-09_NOR-Tg-6m_TS_C6_B_L_final_geolabels.csv\n",
      "Renamed and saved: C:\\Users\\dhers\\OneDrive - UBA\\workshop\\b2-mix\\TS\\final_geolabels\\NOR 6 mth 3xTg_2024-09_NOR-Tg-6m_TS_C6_B_R_final_geolabels.csv\n"
     ]
    }
   ],
   "source": [
    "# Lets rename the labels\n",
    "final_path, groups = rename_labels(reference_path, label_type, objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cum_sums(df, fps = 30):\n",
    "\n",
    "    # Get the actual names of the second and third columns\n",
    "    snd_col = df.columns[1]\n",
    "    trd_col = df.columns[2]\n",
    "\n",
    "    # Calculate cumulative sums\n",
    "    df[f\"{snd_col} \"] = df[snd_col].cumsum() / fps\n",
    "    df[f\"{trd_col} \"] = df[trd_col].cumsum() / fps\n",
    "\n",
    "    # Calculate Discrimination Index\n",
    "    df['Discrimination_Index'] = (\n",
    "        (df[f\"{snd_col} \"] - df[f\"{trd_col} \"]) /\n",
    "        (df[f\"{snd_col} \"] + df[f\"{trd_col} \"])\n",
    "    ) * 100\n",
    "    \n",
    "    # Calculate Discrimination Index 2\n",
    "    df['Discrimination_Index_2'] = ((df[f\"{snd_col} \"] - df[f\"{trd_col} \"]))\n",
    "\n",
    "    # Create a list of column names in the desired order\n",
    "    desired_order = [\"Frame\", f\"{snd_col} \", f\"{trd_col} \", \"Discrimination_Index\", \"Discrimination_Index_2\"]\n",
    "    desired_order = desired_order + [col for col in df.columns if col not in desired_order]\n",
    "\n",
    "    # Reorder columns without losing data\n",
    "    df = df[desired_order]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_positions(position, maxAngle = 45, maxDist = 2.5):\n",
    "\n",
    "    # Extract positions of both objects and bodyparts\n",
    "    obj1 = Point(position, 'obj_1')\n",
    "    obj2 = Point(position, 'obj_2')\n",
    "    nose = Point(position, 'nose')\n",
    "    head = Point(position, 'head')\n",
    "    \n",
    "    # We now filter the frames where the mouse's nose is close to each object\n",
    "    # Find distance from the nose to each object\n",
    "    dist1 = Point.dist(nose, obj1)\n",
    "    dist2 = Point.dist(nose, obj2)\n",
    "    \n",
    "    # Next, we filter the points where the mouse is looking at each object    \n",
    "    # Compute normalized head-nose and head-object vectors\n",
    "    head_nose = Vector(head, nose, normalize = True)\n",
    "    head_obj1 = Vector(head, obj1, normalize = True)\n",
    "    head_obj2 = Vector(head, obj2, normalize = True)\n",
    "    \n",
    "    # Find the angles between the head-nose and head-object vectors\n",
    "    angle1 = Vector.angle(head_nose, head_obj1) # deg\n",
    "    angle2 = Vector.angle(head_nose, head_obj2) # deg\n",
    "    \n",
    "    # Find points where the mouse is looking at the objects\n",
    "    # Im asking the nose be closer to the aimed object to filter distant sighting\n",
    "    towards1 = nose.positions[(angle1 < maxAngle) & (dist1 < maxDist * 3)]\n",
    "    towards2 = nose.positions[(angle2 < maxAngle) & (dist2 < maxDist * 3)]\n",
    "    \n",
    "    return nose, towards1, towards2, obj1, obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_groups(path, name_start, time_limit = None, fps = 30):\n",
    "    \n",
    "    subfolders = path.split(os.path.sep) # list the name of the subfolders in the directory\n",
    "    \n",
    "    # Initialize an empty list to store DataFrames\n",
    "    files = []\n",
    "    bxplt = []\n",
    "    \n",
    "    # Iterate through CSV files in the folder\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.startswith(name_start):\n",
    "        \n",
    "            file_path = os.path.join(path, filename)\n",
    "            file = pd.read_csv(file_path)\n",
    "            file = calc_cum_sums(file, fps)\n",
    "            \n",
    "            distance_path = file_path.replace(f\"{subfolders[-1]}\", \"distances\").replace(f\"{name_start}_\", \"\")\n",
    "            distance = pd.read_csv(distance_path)\n",
    "            file[\"nose_dist_cumsum\"] = distance[\"nose_dist\"].cumsum()\n",
    "            file[\"body_dist_cumsum\"] = distance[\"body_dist\"].cumsum()\n",
    "            \n",
    "            files.append(file)\n",
    "\n",
    "            bx_index = -1\n",
    "            if time_limit is not None:\n",
    "                bx_index = time_limit*fps\n",
    "            \n",
    "            bxplt.append([file.loc[file.index[bx_index], f'{file.columns[1]}'], file.loc[file.index[bx_index], f'{file.columns[2]}']])\n",
    "                \n",
    "    n = len(files) # We find the number of mice to calculate the standard error as std/sqrt(n)\n",
    "    se = np.sqrt(n)\n",
    "    \n",
    "    # Find the minimum length of all files\n",
    "    min_length = min([len(file) for file in files])\n",
    "    if time_limit is not None:\n",
    "        min_length = min(min_length, time_limit*fps)\n",
    "    trunc_files = [file.iloc[:min_length] for file in files]\n",
    "\n",
    "    # Concatenate the list of DataFrames into one DataFrame\n",
    "    all_files = pd.concat(trunc_files, ignore_index=True)\n",
    "    A_files = all_files.columns[1]\n",
    "    B_files = all_files.columns[2]\n",
    "\n",
    "    # Calculate the mean and standard deviation of cumulative sums for each frame\n",
    "    df = all_files.groupby('Frame').agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    bxplt = pd.DataFrame(bxplt, columns = [f'{A_files}', f'{B_files}'])\n",
    "        \n",
    "    # Create a single figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 6))\n",
    "    \n",
    "    df['time_seconds'] = df['Frame'] / fps\n",
    "        \n",
    "    # Distance covered\n",
    "    axes[0, 0].plot(df['time_seconds'], df[(\"nose_dist_cumsum\" ,'mean')], label = \"nose distance\")\n",
    "    axes[0, 0].fill_between(df['time_seconds'], df[(\"nose_dist_cumsum\" ,'mean')] - df[(\"nose_dist_cumsum\", 'std')], df[(\"nose_dist_cumsum\" ,'mean')] + df[(\"nose_dist_cumsum\" ,'std')], alpha=0.2)\n",
    "    axes[0, 0].plot(df['time_seconds'], df[(\"body_dist_cumsum\" ,'mean')], label = \"body distance\")\n",
    "    axes[0, 0].fill_between(df['time_seconds'], df[(\"body_dist_cumsum\" ,'mean')] - df[(\"body_dist_cumsum\", 'std')], df[(\"body_dist_cumsum\" ,'mean')] + df[(\"body_dist_cumsum\" ,'std')], alpha=0.2)\n",
    "    axes[0, 0].set_xlabel('Time (s)')\n",
    "    axes[0, 0].set_xticks([0, 60, 120, 180, 240, 300])\n",
    "    axes[0, 0].set_ylabel('Distance (m)')\n",
    "    axes[0, 0].set_title('Distance Traveled in Habituation')\n",
    "    axes[0, 0].legend(loc='upper left', fancybox=True, shadow=True)\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Object exploration\n",
    "    axes[0, 1].plot(df['time_seconds'], df[(f'{A_files}' ,'mean')], label = A_files, color = 'red', marker='_')\n",
    "    axes[0, 1].fill_between(df['time_seconds'], df[(f'{A_files}' ,'mean')] - df[(f'{A_files}', 'std')] /se, df[(f'{A_files}' ,'mean')] + df[(f'{A_files}' ,'std')] /se, color = 'red', alpha=0.2)\n",
    "    axes[0, 1].plot(df['time_seconds'], df[(f'{B_files}' ,'mean')], label = B_files, color = 'blue', marker='_')\n",
    "    axes[0, 1].fill_between(df['time_seconds'], df[(f'{B_files}' ,'mean')] - df[(f'{B_files}', 'std')] /se, df[(f'{B_files}' ,'mean')] + df[(f'{B_files}' ,'std')] /se, color = 'blue', alpha=0.2)\n",
    "    axes[0, 1].set_xlabel('Time (s)')\n",
    "    axes[0, 1].set_xticks([0, 60, 120, 180, 240, 300])\n",
    "    axes[0, 1].set_ylabel('Exploration Time (s)')\n",
    "    axes[0, 1].set_title('Exploration of objects during TS')\n",
    "    axes[0, 1].legend(loc='upper left', fancybox=True, shadow=True)\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Discrimination Index\n",
    "    axes[1, 0].plot(df['time_seconds'], df[('Discrimination_Index', 'mean')], label='Discrimination Index', color='darkgreen', linestyle='--')\n",
    "    axes[1, 0].fill_between(df['time_seconds'], df[('Discrimination_Index', 'mean')] - df[('Discrimination_Index', 'std')] /se, df[('Discrimination_Index', 'mean')] + df[('Discrimination_Index', 'std')] /se, color='green', alpha=0.2)\n",
    "    axes[1, 0].set_xlabel('Time (s)')\n",
    "    axes[1, 0].set_xticks([0, 60, 120, 180, 240, 300])\n",
    "    axes[1, 0].set_ylabel('DI (%)')\n",
    "    axes[1, 0].set_ylim(-50, 50)\n",
    "    axes[1, 0].axhline(y=0, color='black', linestyle='--', linewidth = 2)\n",
    "    axes[1, 0].set_title('Discrimination Index')\n",
    "    axes[1, 0].legend(loc='upper left', fancybox=True, shadow=True)\n",
    "    axes[1, 0].grid(True)\n",
    "\n",
    "    if time_limit is not None:\n",
    "        axes[0, 0].set_xlim(-10, time_limit + 10)\n",
    "        axes[0, 1].set_xlim(-10, time_limit + 10)\n",
    "        axes[1, 0].set_xlim(-10, time_limit + 10)\n",
    "    \n",
    "    # Boxplot\n",
    "    axes[1, 1].boxplot(bxplt[f'{A_files}'], positions=[1], labels=[f'{A_files}'])\n",
    "    axes[1, 1].boxplot(bxplt[f'{B_files}'], positions=[2], labels=[f'{B_files}'])\n",
    "    \n",
    "    # Replace boxplots with scatter plots with jitter\n",
    "    jitter_amount = 0.05  # Adjust the jitter amount as needed\n",
    "    axes[1, 1].scatter([1 + np.random.uniform(-jitter_amount, jitter_amount) for _ in range(len(bxplt[f'{A_files}']))], bxplt[f'{A_files}'], color='red', alpha=0.7, label=f'{A_files}')\n",
    "    axes[1, 1].scatter([2 + np.random.uniform(-jitter_amount, jitter_amount) for _ in range(len(bxplt[f'{B_files}']))], bxplt[f'{B_files}'], color='blue', alpha=0.7, label=f'{B_files}')\n",
    "    \n",
    "    # Add lines connecting points from the same row\n",
    "    for row in bxplt.index:\n",
    "        index_a = 1\n",
    "        index_b = 2\n",
    "        axes[1, 1].plot([index_a + np.random.uniform(-jitter_amount, jitter_amount), index_b + np.random.uniform(-jitter_amount, jitter_amount)],\n",
    "                        [bxplt.at[row, f'{A_files}'], bxplt.at[row, f'{B_files}']], color='gray', linestyle='-', linewidth=0.5)\n",
    "    # Add mean lines\n",
    "    mean_a = np.mean(bxplt[f'{A_files}'])\n",
    "    mean_b = np.mean(bxplt[f'{B_files}'])\n",
    "    axes[1, 1].axhline(mean_a, color='red', linestyle='--', label=f'Mean {A_files}')\n",
    "    axes[1, 1].axhline(mean_b, color='blue', linestyle='--', label=f'Mean {B_files}')\n",
    "    axes[1, 1].set_ylabel('Exploration Time (s)')\n",
    "    axes[1, 1].set_title('Exploration of objects at the end of TS')\n",
    "\n",
    "    plt.suptitle(f\"Analysis of {subfolders[-3]}: {name_start}\", y=0.98)  # Add DataFrame name as the overall title\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(os.path.dirname(path), f\"{name_start}_({subfolders[-1]}).png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in groups:\n",
    "    plot_groups(final_path, group, time_limit = None, fps = video_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all(path, name_start, fps = 30):\n",
    "    \n",
    "    subfolders = path.split(os.path.sep) # list the name of the subfolders in the directory\n",
    "    \n",
    "    os.makedirs(os.path.join(path, \"plots\"), exist_ok = True)\n",
    "    \n",
    "    # Iterate through CSV files in the folder\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.startswith(name_start):\n",
    "        \n",
    "            file_path = os.path.join(path, filename)\n",
    "            file = pd.read_csv(file_path)\n",
    "            file = calc_cum_sums(file, fps)\n",
    "            \n",
    "            distance_path = file_path.replace(f\"{subfolders[-1]}\", \"distances\").replace(f\"{name_start}_\", \"\")\n",
    "            distance = pd.read_csv(distance_path)\n",
    "            file[\"nose_dist_cumsum\"] = distance[\"nose_dist\"].cumsum()\n",
    "            file[\"body_dist_cumsum\"] = distance[\"body_dist\"].cumsum()\n",
    "                        \n",
    "            position_file_path = file_path.replace(f\"{subfolders[-1]}\", \"position\").replace(f\"{name_start}_\", \"\")\n",
    "            position = pd.read_csv(position_file_path)\n",
    "            \n",
    "            # Create a single figure\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(16, 8))\n",
    "            \n",
    "            file['time_seconds'] = file['Frame'] / fps\n",
    "            \n",
    "            # Distance covered\n",
    "            axes[0, 0].plot(file['time_seconds'], file['nose_dist_cumsum'], label='Nose Distance')\n",
    "            axes[0, 0].plot(file['time_seconds'], file['body_dist_cumsum'], label='Body Distance')\n",
    "            axes[0, 0].set_xlabel('Time (s)')\n",
    "            axes[0, 0].set_xticks([0, 60, 120, 180, 240, 300])\n",
    "            axes[0, 0].set_ylabel('Distance Traveled (m)')\n",
    "            # axes[0, 0].set_ylim(0, 4000)\n",
    "            axes[0, 0].set_title('Hab')\n",
    "            axes[0, 0].legend(loc='upper left', fancybox=True, shadow=True)\n",
    "            axes[0, 0].grid(True)\n",
    "            \n",
    "            # Object exploration\n",
    "            axes[0, 1].plot(file['time_seconds'], file[f'{file.columns[1]}'], label=f'{file.columns[1]}', color='red', marker='_')\n",
    "            axes[0, 1].plot(file['time_seconds'], file[f'{file.columns[2]}'], label=f'{file.columns[2]}', color='blue', marker='_')\n",
    "            axes[0, 1].set_xlabel('Time (s)')\n",
    "            axes[0, 1].set_xticks([0, 60, 120, 180, 240, 300])\n",
    "            axes[0, 1].set_ylabel('Exploration Time (s)')\n",
    "            axes[0, 1].set_title('file')\n",
    "            axes[0, 1].legend(loc='upper left', fancybox=True, shadow=True)\n",
    "            axes[0, 1].grid(True)\n",
    "    \n",
    "            # Discrimination Index\n",
    "            axes[1, 0].plot(file['time_seconds'], file['Discrimination_Index'], label='Discrimination Index', color='green', linestyle='--', linewidth=3)\n",
    "            axes[1, 0].set_xlabel('Time (s)')\n",
    "            axes[1, 0].set_xticks([0, 60, 120, 180, 240, 300])\n",
    "            axes[1, 0].set_ylabel('DI (%)')\n",
    "            # axes[1, 0].set_ylim(-50, 50)\n",
    "            axes[1, 0].set_title('Discrimination Index')\n",
    "            axes[1, 0].legend(loc='upper left', fancybox=True, shadow=True)\n",
    "            axes[1, 0].grid(True)\n",
    "            axes[1, 0].axhline(y=0, color='black', linestyle=':', linewidth=3)\n",
    "            \n",
    "            # Positions\n",
    "            \n",
    "            nose, towards1, towards2, obj1, obj2 = Extract_positions(position)\n",
    "\n",
    "            \"\"\"\n",
    "            Finally, we can plot the points that match both conditions\n",
    "            \"\"\"\n",
    "            \n",
    "            # Plot the nose positions\n",
    "            axes[1, 1].plot(*nose.positions.T, \".\", color = \"grey\", alpha = 0.15)\n",
    "            \n",
    "            # Plot the filtered points\n",
    "            axes[1, 1].plot(*towards1.T, \".\", label = \"Oriented towards 1\", color = \"brown\", alpha = 0.3)\n",
    "            axes[1, 1].plot(*towards2.T, \".\", label = \"Oriented towards 2\", color = \"teal\", alpha = 0.3)\n",
    "            \n",
    "            # Plot the objects\n",
    "            axes[1, 1].plot(*obj1.positions[0], \"s\", lw = 20, label = \"Object 1\", color = \"blue\", markersize = 9, markeredgecolor = \"blue\")\n",
    "            axes[1, 1].plot(*obj2.positions[0], \"o\", lw = 20, label = \"Object 2\", color = \"red\", markersize = 10, markeredgecolor = \"darkred\")\n",
    "            \n",
    "            # Plot the circles of distance criteria\n",
    "            axes[1, 1].add_artist(Circle(obj1.positions[0], 2.5, color = \"orange\", alpha = 0.3))\n",
    "            axes[1, 1].add_artist(Circle(obj2.positions[0], 2.5, color = \"orange\", alpha = 0.3))\n",
    "            \n",
    "            axes[1, 1].axis('equal')\n",
    "            axes[1, 1].set_xlabel(\"Horizontal position (cm)\")\n",
    "            axes[1, 1].set_ylabel(\"Vertical position (cm)\")\n",
    "            axes[1, 1].legend(loc='upper left', ncol=2, fancybox=True, shadow=True)\n",
    "            axes[1, 1].grid(True)\n",
    "            \n",
    "            file_name = os.path.basename(file_path)\n",
    "            \n",
    "            plt.suptitle(f\"Analysis of {subfolders[-3]}: {file_name}\", y=0.98)  # Add DataFrame name as the overall title\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(path, \"plots\", f\"{file_name}_plot.png\"))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for group in groups:\n",
    "#     plot_all(final_path, group, fps = video_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_experiment(path, group_list, time_limit = None, fps = 30):\n",
    "    \n",
    "    subfolders = path.split(os.path.sep) # list the name of the subfolders in the directory\n",
    "    \n",
    "    # Create a single figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 8))\n",
    "    \n",
    "    bxplt_positions = list(range(1, len(group_list) + 1))\n",
    "        \n",
    "    for i, name_start in enumerate(group_list):\n",
    "        # Initialize an empty list to store DataFrames\n",
    "        files = []\n",
    "        bxplt = []\n",
    "        \n",
    "        # Iterate through CSV files in the folder\n",
    "        for filename in os.listdir(path):\n",
    "            if filename.startswith(name_start):\n",
    "            \n",
    "                file_path = os.path.join(path, filename)\n",
    "                file = pd.read_csv(file_path)\n",
    "                file = calc_cum_sums(file, fps)\n",
    "                \n",
    "                distance_path = file_path.replace(f\"{subfolders[-1]}\", \"distances\").replace(f\"{name_start}_\", \"\")\n",
    "                distance = pd.read_csv(distance_path)\n",
    "                file[\"nose_dist_cumsum\"] = distance[\"nose_dist\"].cumsum()\n",
    "                file[\"body_dist_cumsum\"] = distance[\"body_dist\"].cumsum()\n",
    "                \n",
    "                files.append(file)\n",
    "\n",
    "                bx_index = -1\n",
    "                if time_limit is not None:\n",
    "                    bx_index = time_limit*fps\n",
    "                \n",
    "                bxplt.append(file.loc[file.index[bx_index], \"Discrimination_Index\"])\n",
    "                    \n",
    "        n = len(files) # We find the number of mice to calculate the standard error as std/sqrt(n)\n",
    "        se = np.sqrt(n)\n",
    "        \n",
    "        # Find the minimum length of all files\n",
    "        min_length = min([len(file) for file in files])\n",
    "        if time_limit is not None:\n",
    "            min_length = min(min_length, time_limit*fps)\n",
    "        trunc_files = [file.iloc[:min_length] for file in files]\n",
    "\n",
    "        # Concatenate the list of DataFrames into one DataFrame\n",
    "        all_files = pd.concat(trunc_files, ignore_index=True)\n",
    "        A_files = all_files.columns[1]\n",
    "        B_files = all_files.columns[2]\n",
    "\n",
    "        # Calculate the mean and standard deviation of cumulative sums for each frame\n",
    "        df = all_files.groupby('Frame').agg(['mean', 'std']).reset_index()\n",
    "        \n",
    "        bxplt = pd.DataFrame(bxplt)\n",
    "        \n",
    "        df['time_seconds'] = df['Frame'] / fps\n",
    "        \n",
    "        # Distance covered\n",
    "        axes[0, 0].plot(df['time_seconds'], df[(\"nose_dist_cumsum\" ,'mean')], label = f'Nose {name_start}')\n",
    "        axes[0, 0].fill_between(df['time_seconds'], df[(\"nose_dist_cumsum\" ,'mean')] - df[(\"nose_dist_cumsum\", 'std')], df[(\"nose_dist_cumsum\" ,'mean')] + df[(\"nose_dist_cumsum\" ,'std')], alpha=0.2)\n",
    "        axes[0, 0].plot(df['time_seconds'], df[(\"body_dist_cumsum\" ,'mean')], label = f'Body {name_start}')\n",
    "        axes[0, 0].fill_between(df['time_seconds'], df[(\"body_dist_cumsum\" ,'mean')] - df[(\"body_dist_cumsum\", 'std')], df[(\"body_dist_cumsum\" ,'mean')] + df[(\"body_dist_cumsum\" ,'std')], alpha=0.2)\n",
    "        axes[0, 0].set_xlabel('Time (s)')\n",
    "        axes[0, 0].set_xticks([0, 60, 120, 180, 240, 300])\n",
    "        axes[0, 0].set_ylabel('Distance (m)')\n",
    "        # axes[0, 0].set_ylim(0, 4000)\n",
    "        axes[0, 0].set_title('Distance Traveled')\n",
    "        axes[0, 0].legend(loc='upper left', fancybox=True, shadow=True)\n",
    "        axes[0, 0].grid(True)\n",
    "        \n",
    "        # Object exploration\n",
    "        axes[0, 1].plot(df['time_seconds'], df[(f'{A_files}' ,'mean')], label = f'{A_files}{name_start}', marker='_')\n",
    "        axes[0, 1].fill_between(df['time_seconds'], df[(f'{A_files}' ,'mean')] - df[(f'{A_files}', 'std')] /se, df[(f'{A_files}' ,'mean')] + df[(f'{A_files}' ,'std')] /se, alpha=0.2)\n",
    "        axes[0, 1].plot(df['time_seconds'], df[(f'{B_files}' ,'mean')], label = f'{B_files}{name_start}', marker='_')\n",
    "        axes[0, 1].fill_between(df['time_seconds'], df[(f'{B_files}' ,'mean')] - df[(f'{B_files}', 'std')] /se, df[(f'{B_files}' ,'mean')] + df[(f'{B_files}' ,'std')] /se, alpha=0.2)\n",
    "        axes[0, 1].set_xlabel('Time (s)')\n",
    "        axes[0, 1].set_xticks([0, 60, 120, 180, 240, 300])\n",
    "        axes[0, 1].set_ylabel('Exploration Time (s)')\n",
    "        axes[0, 1].set_title('Exploration of objects')\n",
    "        axes[0, 1].legend(loc='upper left', fancybox=True, shadow=True)\n",
    "        axes[0, 1].grid(True)\n",
    "        \n",
    "        # Discrimination Index\n",
    "        axes[1, 0].plot(df['time_seconds'], df[('Discrimination_Index', 'mean')], label=f'{name_start}', linestyle='--')\n",
    "        axes[1, 0].fill_between(df['time_seconds'], df[('Discrimination_Index', 'mean')] - df[('Discrimination_Index', 'std')] /se, df[('Discrimination_Index', 'mean')] + df[('Discrimination_Index', 'std')] /se, alpha=0.2)\n",
    "        axes[1, 0].set_xlabel('Time (s)')\n",
    "        axes[1, 0].set_xticks([0, 60, 120, 180, 240, 300])\n",
    "        axes[1, 0].set_ylabel('DI (%)')\n",
    "        axes[1, 0].set_ylim(-50, 50)\n",
    "        axes[1, 0].axhline(y=0, color='black', linestyle='--', linewidth = 2)\n",
    "        axes[1, 0].set_title('Discrimination Index')\n",
    "        axes[1, 0].legend(loc='upper left', fancybox=True, shadow=True)\n",
    "        axes[1, 0].grid(True)\n",
    "\n",
    "        if time_limit is not None:\n",
    "            axes[0, 0].set_xlim(-10, time_limit + 10)\n",
    "            axes[0, 1].set_xlim(-10, time_limit + 10)\n",
    "            axes[1, 0].set_xlim(-10, time_limit + 10)\n",
    "        \n",
    "        # Boxplot\n",
    "        axes[1, 1].boxplot(bxplt[0], positions=[bxplt_positions[i]], labels = [f'{name_start}'])\n",
    "        \n",
    "        # Replace boxplots with scatter plots with jitter\n",
    "        jitter_amount = 0.05  # Adjust the jitter amount as needed\n",
    "        axes[1, 1].scatter([i + 1 + np.random.uniform(-jitter_amount, jitter_amount) for _ in range(len(bxplt[0]))], bxplt[0], alpha=0.7, label=f'{name_start}')\n",
    "        \n",
    "        axes[1, 1].axhline(y=0, color='black', linestyle='--', linewidth = 2)\n",
    "        axes[1, 1].set_ylabel('DI (%)')\n",
    "        axes[1, 1].set_title('Discrimination Index by group')\n",
    "    \n",
    "    plt.suptitle(f\"Analysis of experiment: {subfolders[-3]}\", y=0.98)  # Add DataFrame name as the overall title\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(os.path.dirname(path), f\"{subfolders[-3]}_({subfolders[-1]}).png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_experiment(final_path, groups, time_limit = t_lim, fps = video_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to move to plotly\n",
    "\n",
    "def plot_groups_plotly(path, name_start, time_limit = None, fps = video_fps):\n",
    "    \n",
    "    # list the name of the subfolders in the directory to access the distance files\n",
    "    subfolders = path.split(os.path.sep) \n",
    "    \n",
    "    # Initialize an empty list to store DataFrames\n",
    "    files = []\n",
    "    bxplt = []\n",
    "    \n",
    "    # Iterate through CSV files in the folder\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.startswith(name_start):\n",
    "        \n",
    "            file_path = os.path.join(path, filename)\n",
    "            file = pd.read_csv(file_path)\n",
    "            file = calc_cum_sums(file, time_limit, fps)\n",
    "            \n",
    "            distance_path = file_path.replace(f\"{subfolders[-1]}\", \"distances\").replace(f\"{name_start}_\", \"\")\n",
    "            distance = pd.read_csv(distance_path)\n",
    "            file[\"nose_dist\"] = distance[\"nose_dist\"].cumsum()\n",
    "            file[\"body_dist\"] = distance[\"body_dist\"].cumsum()\n",
    "            \n",
    "            files.append(file)\n",
    "            \n",
    "            bxplt.append([file.loc[file.index[-1], f'{file.columns[1]}'], file.loc[file.index[-1], f'{file.columns[2]}']])\n",
    "                \n",
    "    n = len(files) # We find the number of mice to calculate the standard error as std/sqrt(n)\n",
    "    se = np.sqrt(n)\n",
    "    \n",
    "    # Concatenate the list of DataFrames into one DataFrame\n",
    "    all_files = pd.concat(files, ignore_index=True)\n",
    "    A_files = all_files.columns[1]\n",
    "    B_files = all_files.columns[2]\n",
    "\n",
    "    # Calculate the mean and standard deviation of cumulative sums for each frame\n",
    "    df = all_files.groupby('Frame').agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    bxplt = pd.DataFrame(bxplt, columns = [f'{A_files}', f'{B_files}'])\n",
    "\n",
    "    df['time_seconds'] = df['Frame'] / fps\n",
    "\n",
    "    # Creating subplots (2 rows, 2 columns)\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Distance Traveled in Habituation', \n",
    "                        'Exploration of objects during TS',\n",
    "                        'Discrimination Index', \n",
    "                        'Exploration of objects at the end of TS'),\n",
    "        vertical_spacing=0.15,\n",
    "        horizontal_spacing=0.1\n",
    "    )\n",
    "\n",
    "    # Plot 1: Distance covered (Nose and Body)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['time_seconds'], y=df[(\"nose_dist\", 'mean')],\n",
    "                   mode='lines', name=\"Nose Distance\", line=dict(color='orange'), showlegend=True),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['time_seconds'], y=df[(\"nose_dist\", 'mean')] - df[(\"nose_dist\", 'std')],\n",
    "                   fill=None, mode='lines', line=dict(width=0), showlegend=False),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['time_seconds'], y=df[(\"nose_dist\", 'mean')] + df[(\"nose_dist\", 'std')],\n",
    "                   fill='tonexty', mode='lines', fillcolor='rgba(255,165,0,0.2)', line=dict(width=0), showlegend=False),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['time_seconds'], y=df[(\"body_dist\", 'mean')],\n",
    "                   mode='lines', name=\"Body Distance\", line=dict(color='blue'), showlegend=True),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['time_seconds'], y=df[(\"body_dist\", 'mean')] - df[(\"body_dist\", 'std')],\n",
    "                   fill=None, mode='lines', line=dict(width=0), showlegend=False),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['time_seconds'], y=df[(\"body_dist\", 'mean')] + df[(\"body_dist\", 'std')],\n",
    "                   fill='tonexty', mode='lines', fillcolor='rgba(0,0,255,0.2)', line=dict(width=0), showlegend=False),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Plot 2: Object exploration (A and B files)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['time_seconds'], y=df[(f'{A_files}', 'mean')],\n",
    "                   mode='markers', name=A_files, marker=dict(color='red'), showlegend=True),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['time_seconds'], y=df[(f'{A_files}', 'mean')] - df[(f'{A_files}', 'std')] / se,\n",
    "                   fill=None, mode='lines', line=dict(width=0), showlegend=False),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['time_seconds'], y=df[(f'{A_files}', 'mean')] + df[(f'{A_files}', 'std')] / se,\n",
    "                   fill='tonexty', mode='lines', fillcolor='rgba(255,0,0,0.2)', line=dict(width=0), showlegend=False),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['time_seconds'], y=df[(f'{B_files}', 'mean')],\n",
    "                   mode='markers', name=B_files, marker=dict(color='blue'), showlegend=True),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['time_seconds'], y=df[(f'{B_files}', 'mean')] - df[(f'{B_files}', 'std')] / se,\n",
    "                   fill=None, mode='lines', line=dict(width=0), showlegend=False),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['time_seconds'], y=df[(f'{B_files}', 'mean')] + df[(f'{B_files}', 'std')] / se,\n",
    "                   fill='tonexty', mode='lines', fillcolor='rgba(0,0,255,0.2)', line=dict(width=0), showlegend=False),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # Plot 3: Discrimination Index\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['time_seconds'], y=df[('Discrimination_Index', 'mean')],\n",
    "                   mode='lines', name=\"Discrimination Index\", line=dict(color='darkgreen', dash='dash'), showlegend=True),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['time_seconds'], y=df[('Discrimination_Index', 'mean')] - df[('Discrimination_Index', 'std')] / se,\n",
    "                   fill=None, mode='lines', line=dict(width=0), showlegend=False),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['time_seconds'], y=df[('Discrimination_Index', 'mean')] + df[('Discrimination_Index', 'std')] / se,\n",
    "                   fill='tonexty', mode='lines', fillcolor='rgba(0,100,0,0.2)', line=dict(width=0), showlegend=False),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    # Plot 4: Boxplot (Scatter and Jitter)\n",
    "    jitter_amount = 0.05\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=[1 + np.random.uniform(-jitter_amount, jitter_amount) for _ in range(len(bxplt[f'{A_files}']))],\n",
    "                   y=bxplt[f'{A_files}'], mode='markers', name=A_files, marker=dict(color='red')),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=[2 + np.random.uniform(-jitter_amount, jitter_amount) for _ in range(len(bxplt[f'{B_files}']))],\n",
    "                   y=bxplt[f'{B_files}'], mode='markers', name=B_files, marker=dict(color='blue')),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "    # Connecting lines\n",
    "    for row in bxplt.index:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=[1, 2], y=[bxplt.at[row, f'{A_files}'], bxplt.at[row, f'{B_files}']],\n",
    "                       mode='lines', line=dict(color='gray', width=0.5), showlegend=False),\n",
    "            row=2, col=2\n",
    "        )\n",
    "\n",
    "    # Mean lines for boxplot\n",
    "    mean_a = np.mean(bxplt[f'{A_files}'])\n",
    "    mean_b = np.mean(bxplt[f'{B_files}'])\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=[1, 1], y=[mean_a, mean_a], mode='lines', line=dict(color='red', dash='dash'), name=f'Mean {A_files}'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=[2, 2], y=[mean_b, mean_b], mode='lines', line=dict(color='blue', dash='dash'), name=f'Mean {B_files}'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "    # Layout adjustments\n",
    "    fig.update_xaxes(tickvals=[0, 60, 120, 180, 240, 300], title_text=\"Time (s)\", row=1, col=1)\n",
    "    fig.update_xaxes(tickvals=[0, 60, 120, 180, 240, 300], title_text=\"Time (s)\", row=1, col=2)\n",
    "    fig.update_xaxes(tickvals=[0, 60, 120, 180, 240, 300], title_text=\"Time (s)\", row=2, col=1)\n",
    "\n",
    "    fig.update_yaxes(title_text=\"Distance (m)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Exploration Time (s)\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"DI (%)\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Exploration Time (s)\", row=2, col=2)\n",
    "\n",
    "    # Set the overall title\n",
    "    fig.update_layout(title_text=f\"Analysis of {subfolders[-3]}: {name_start}\", \n",
    "                      title_x=0.5, \n",
    "                      width=720, height=480,  # Set plot size\n",
    "                      showlegend=True)\n",
    "\n",
    "    fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlc3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
