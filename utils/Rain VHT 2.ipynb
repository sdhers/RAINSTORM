{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "from tkinter import Tk, filedialog, messagebox, Label, Entry, Button, Toplevel, Spinbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_video_files() -> dict:\n",
    "    \"\"\"Select video files using a file dialog and return a dictionary.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with video file paths as keys and empty parameter dictionaries as values.\n",
    "    \"\"\"\n",
    "    # Initialize Tkinter and hide the root window\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    \n",
    "    # Open file dialog to select video files\n",
    "    video_files = filedialog.askopenfilenames(\n",
    "        title=\"Select Video Files\",\n",
    "        filetypes=[(\"Video Files\", \"*.mp4 *.avi *.mkv *.mov\")]\n",
    "    )\n",
    "    if not video_files:\n",
    "        raise ValueError(\"No video files selected.\")\n",
    "    \n",
    "    print(f\"Selected {len(video_files)} videos.\")\n",
    "\n",
    "    # Create a dictionary with filenames as keys and an empty dictionary for parameters\n",
    "    video_dict = {file: {\"trim\": None, \"crop\": None, \"align\": None, \"resolution\": None, \"fps\": None} for file in video_files}\n",
    "\n",
    "    return video_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 1 videos.\n"
     ]
    }
   ],
   "source": [
    "video_dict = select_video_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_info(file_path):\n",
    "    \"\"\"Extracts all possible metadata from a video file and returns a dictionary.\"\"\"\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open {file_path}.\")\n",
    "        return None\n",
    "\n",
    "    video_info = {\n",
    "        \"width\": int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        \"height\": int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    "        \"fps\": int(cap.get(cv2.CAP_PROP_FPS)),\n",
    "        \"frame_count\": int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
    "        \"duration\": int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) / max(1, cap.get(cv2.CAP_PROP_FPS)),\n",
    "        \"codec\": int(cap.get(cv2.CAP_PROP_FOURCC)),\n",
    "        \"bitrate\": int(cap.get(cv2.CAP_PROP_BITRATE)) if hasattr(cv2, \"CAP_PROP_BITRATE\") else None\n",
    "    }\n",
    "\n",
    "    cap.release()\n",
    "    return video_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoEditor:\n",
    "    def __init__(self, root, video_dict):\n",
    "        self.video_dict = video_dict\n",
    "        self.video_files = list(video_dict.keys())\n",
    "        self.current_file = self.video_files[0] if self.video_files else None\n",
    "\n",
    "        # Store all video metadata in a dictionary\n",
    "        self.video_info = {file: get_video_info(file) for file in self.video_files}\n",
    "\n",
    "        # Read resolution and FPS from video_info\n",
    "        if self.current_file and self.video_info[self.current_file]:\n",
    "            self.original_width = self.video_info[self.current_file][\"width\"]\n",
    "            self.original_height = self.video_info[self.current_file][\"height\"]\n",
    "            self.original_fps = self.video_info[self.current_file][\"fps\"]\n",
    "            self.aspect_ratio = self.original_height / self.original_width\n",
    "        else:\n",
    "            print(\"Error: Could not read video info.\")\n",
    "            return\n",
    "\n",
    "        # Create GUI window\n",
    "        self.window = Toplevel(root)\n",
    "        self.window.title(\"Video Editor\")\n",
    "        self.window.geometry(\"250x250\")\n",
    "\n",
    "        # Labels & Input Fields\n",
    "        Label(self.window, text=\"Start Time (mm:ss)\").pack()\n",
    "        self.start_time = Entry(self.window)\n",
    "        self.start_time.insert(0, \"00:00\")\n",
    "        self.start_time.pack()\n",
    "\n",
    "        Label(self.window, text=\"End Time (mm:ss)\").pack()\n",
    "        self.end_time = Entry(self.window)\n",
    "        self.end_time.insert(0, \"00:05\")\n",
    "        self.end_time.pack()\n",
    "\n",
    "        Label(self.window, text=f\"Resolution (default {self.original_width}x{self.original_height})\").pack()\n",
    "        self.width_spin = Spinbox(self.window, from_=100, to=4000, command=self.update_height)\n",
    "        self.width_spin.pack()\n",
    "        self.width_spin.delete(0, \"end\")\n",
    "        self.width_spin.insert(0, str(self.original_width))\n",
    "\n",
    "        self.height_spin = Spinbox(self.window, from_=100, to=4000, command=self.update_width)\n",
    "        self.height_spin.pack()\n",
    "        self.height_spin.delete(0, \"end\")\n",
    "        self.height_spin.insert(0, str(self.original_height))\n",
    "\n",
    "        Label(self.window, text=f\"FPS (default {self.original_fps})\").pack()\n",
    "        self.fps_spin = Spinbox(self.window, from_=1, to=200)\n",
    "        self.fps_spin.pack()\n",
    "        self.fps_spin.delete(0, \"end\")\n",
    "        self.fps_spin.insert(0, str(self.original_fps))\n",
    "\n",
    "        Button(self.window, text=\"Apply Settings\", command=self.apply_settings).pack()\n",
    "\n",
    "    def update_height(self):\n",
    "        \"\"\"Automatically adjust height based on width to maintain aspect ratio.\"\"\"\n",
    "        try:\n",
    "            width = int(self.width_spin.get())\n",
    "            height = int(width * self.aspect_ratio)\n",
    "            self.height_spin.delete(0, \"end\")\n",
    "            self.height_spin.insert(0, str(height))\n",
    "        except ValueError:\n",
    "            pass  # Ignore invalid input\n",
    "\n",
    "    def update_width(self):\n",
    "        \"\"\"Automatically adjust width based on height to maintain aspect ratio.\"\"\"\n",
    "        try:\n",
    "            height = int(self.height_spin.get())\n",
    "            width = int(height / self.aspect_ratio)\n",
    "            self.width_spin.delete(0, \"end\")\n",
    "            self.width_spin.insert(0, str(width))\n",
    "        except ValueError:\n",
    "            pass  # Ignore invalid input\n",
    "\n",
    "    def convert_time(self, time_str):\n",
    "        \"\"\"Convert mm:ss format to seconds.\"\"\"\n",
    "        try:\n",
    "            minutes, seconds = map(int, time_str.split(\":\"))\n",
    "            return minutes * 60 + seconds\n",
    "        except ValueError:\n",
    "            return None  # Return None if input is invalid\n",
    "\n",
    "    def apply_settings(self):\n",
    "        \"\"\"Apply trim, resize, and FPS settings to all videos in the dictionary.\"\"\"\n",
    "        trim_start = self.convert_time(self.start_time.get())\n",
    "        trim_end = self.convert_time(self.end_time.get())\n",
    "        width = int(self.width_spin.get())\n",
    "        height = int(self.height_spin.get())\n",
    "        fps = int(self.fps_spin.get())\n",
    "\n",
    "        # Validate trim times\n",
    "        if trim_start is None or trim_end is None or trim_start >= trim_end:\n",
    "            print(\"Invalid trim times. No changes applied.\")\n",
    "            return\n",
    "\n",
    "        # Update all videos in the dictionary\n",
    "        for video_path in self.video_dict.keys():\n",
    "            self.video_dict[video_path][\"trim\"] = {\"start\": trim_start, \"end\": trim_end}\n",
    "            self.video_dict[video_path][\"resolution\"] = {\"width\": width, \"height\": height}\n",
    "            self.video_dict[video_path][\"fps\"] = fps\n",
    "\n",
    "        print(\"Settings applied to all videos.\")\n",
    "\n",
    "        # Close the window\n",
    "        self.window.quit()\n",
    "        self.window.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings applied to all videos.\n"
     ]
    }
   ],
   "source": [
    "root = Tk()\n",
    "root.withdraw()  # Hide the main window        \n",
    "VideoEditor(root, video_dict)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_frames(video_files: list) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Merge the first frame of each video file into a single image.\n",
    "\n",
    "    Args:\n",
    "        video_files (list): List of video files.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Merged image.\n",
    "    \"\"\"\n",
    "    merged_image = None\n",
    "    \n",
    "    if len(video_files) > 1:\n",
    "        for video_file in video_files:\n",
    "            cap = cv2.VideoCapture(video_file)\n",
    "            success, frame = cap.read()\n",
    "            cap.release()\n",
    "            \n",
    "            if not success:\n",
    "                print(f\"Could not read first frame of {video_file}\")\n",
    "                continue\n",
    "            \n",
    "            # Calculate transparency\n",
    "            transparency = round(1 / len(video_files), 4)\n",
    "            transparent_frame = (frame * transparency).astype(np.uint8)\n",
    "            \n",
    "            if merged_image is None:\n",
    "                # Initialize merged image\n",
    "                merged_image = np.zeros_like(transparent_frame)\n",
    "            \n",
    "            # Add transparent frame to the merged image\n",
    "            merged_image = cv2.add(merged_image, transparent_frame)\n",
    "    \n",
    "    else:\n",
    "        video_file = video_files[0]\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        selected_frame_indices = [1, total_frames//2, total_frames-1] # merge the first, middle, and last frames\n",
    "\n",
    "        for frame_idx in selected_frame_indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            success, frame = cap.read()\n",
    "\n",
    "            if not success:\n",
    "                print(f\"Could not read frame {frame_idx} from {video_file}\")\n",
    "                continue\n",
    "\n",
    "            # Calculate transparency\n",
    "            transparency = 1/3 # set transparency to 1/3 for each of the three frames\n",
    "            transparent_frame = (frame * transparency).astype(np.uint8)\n",
    "            \n",
    "            if merged_image is None:\n",
    "                # Initialize merged image\n",
    "                merged_image = np.zeros_like(transparent_frame)\n",
    "            \n",
    "            # Add transparent frame to the merged image\n",
    "            merged_image = cv2.add(merged_image, transparent_frame)\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "    return merged_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom_in_display(frame, x, y, zoom_scale = 5, zoom_window_size = 25):\n",
    "    # Create zoomed-in display\n",
    "    x1 = max(0, x - zoom_window_size)\n",
    "    x2 = min(frame.shape[1], x + zoom_window_size)\n",
    "    y1 = max(0, y - zoom_window_size)\n",
    "    y2 = min(frame.shape[0], y + zoom_window_size)\n",
    "\n",
    "    zoomed_area = frame[y1:y2, x1:x2]\n",
    "    \n",
    "    # Resize zoomed-in area\n",
    "    zoomed_area_resized = cv2.resize(zoomed_area, None, fx=zoom_scale, fy=zoom_scale, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Add crosshair to the center\n",
    "    center_x = zoomed_area_resized.shape[1] // 2\n",
    "    center_y = zoomed_area_resized.shape[0] // 2\n",
    "    color = (0, 255, 0)  # Black crosshair\n",
    "    thickness = 2\n",
    "    line_length = 20  # Length of crosshair lines\n",
    "\n",
    "    # Draw vertical line\n",
    "    cv2.line(zoomed_area_resized, (center_x, center_y - line_length), (center_x, center_y + line_length), color, thickness)\n",
    "    # Draw horizontal line\n",
    "    cv2.line(zoomed_area_resized, (center_x - line_length, center_y), (center_x + line_length, center_y), color, thickness)\n",
    "\n",
    "    if x2 > (frame.shape[1] - zoomed_area_resized.shape[1] - 10) and y1 < (10 + zoomed_area_resized.shape[0]):\n",
    "        # Overlay zoomed-in area in the top-left corner of the frame\n",
    "        overlay_x1 = 10\n",
    "        overlay_x2 = 10 + zoomed_area_resized.shape[1]\n",
    "        overlay_y1 = 10\n",
    "        overlay_y2 = 10 + zoomed_area_resized.shape[0]\n",
    "    \n",
    "    else:\n",
    "        # Overlay zoomed-in area in the top-right corner of the frame\n",
    "        overlay_x1 = frame.shape[1] - zoomed_area_resized.shape[1] - 10\n",
    "        overlay_x2 = frame.shape[1] - 10\n",
    "        overlay_y1 = 10\n",
    "        overlay_y2 = 10 + zoomed_area_resized.shape[0]\n",
    "\n",
    "    placement = (overlay_x1, overlay_x2, overlay_y1, overlay_y2)\n",
    "\n",
    "    return zoomed_area_resized, placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_point_pairs(video_dict: dict) -> dict:\n",
    "    \"\"\"Select two alignment points for each video and update the video_dict.\n",
    "\n",
    "    Args:\n",
    "        video_dict (dict): Dictionary of video files with parameters.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated dictionary with alignment points added.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize Tkinter and hide the root window\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "\n",
    "    # Define callback function for point selection\n",
    "    def select_points(event, x, y, flags, param):\n",
    "        nonlocal frame, temp_frame, current_point, confirmed_points\n",
    "\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            # Update the current point with the clicked position\n",
    "            current_point = (x, y)\n",
    "            # Draw the current point\n",
    "            cv2.circle(temp_frame, current_point, 3, (0, 255, 0), -1)\n",
    "            # Draw the confirmed points on the frame\n",
    "            for point in confirmed_points: \n",
    "                cv2.circle(temp_frame, point, 3, (0, 0, 255), -1)\n",
    "            # Display the frame\n",
    "            cv2.imshow('Select Points', temp_frame)\n",
    "        \n",
    "        # Reset the frame\n",
    "        temp_frame = frame.copy()\n",
    "\n",
    "        # Draw the current point\n",
    "        if current_point is not None:\n",
    "            cv2.circle(temp_frame, current_point, 3, (0, 255, 0), -1)\n",
    "        # Draw the confirmed points on the frame\n",
    "        for point in confirmed_points:\n",
    "            cv2.circle(temp_frame, point, 3, (0, 0, 255), -1)\n",
    "        # Display the zoomed-in area\n",
    "        zoomed_area_resized, placement = zoom_in_display(temp_frame, x, y)\n",
    "        overlay_x1, overlay_x2, overlay_y1, overlay_y2 = placement\n",
    "        temp_frame[overlay_y1:overlay_y2, overlay_x1:overlay_x2] = zoomed_area_resized\n",
    "        # Display the frame\n",
    "        cv2.imshow('Select Points', temp_frame)\n",
    "\n",
    "    def confirm_point():\n",
    "        \"\"\"Confirm the current point and add it to the list.\"\"\"\n",
    "        nonlocal temp_frame, confirmed_points, current_point\n",
    "        if current_point is not None:\n",
    "            confirmed_points.append(current_point)\n",
    "            # Draw the confirmed points on the frame\n",
    "            for point in confirmed_points: \n",
    "                cv2.circle(temp_frame, point, 3, (0, 0, 255), -1)\n",
    "            # Display the frame\n",
    "            cv2.imshow('Select Points', temp_frame)\n",
    "            current_point = None\n",
    "            print(f\"Point confirmed: {confirmed_points[-1]}\")  # Feedback to the user\n",
    "    \n",
    "    # Step 1: Extract first frames and collect two points for each video\n",
    "    for video_path in video_dict.keys():\n",
    "        frame = merge_frames([video_path]) # we make video_path a list because merge_frames expects a list\n",
    "        confirmed_points = []  # Store the two confirmed points for this video\n",
    "        current_point = None  # Temporary point being adjusted\n",
    "        temp_frame = frame.copy()  # Create a copy of the frame\n",
    "\n",
    "        # Run the mouse callback with the frame and confirmed points\n",
    "        cv2.imshow('Select Points', frame)\n",
    "        cv2.setMouseCallback('Select Points', select_points)\n",
    "\n",
    "        # Wait for user to confirm two points\n",
    "        while len(confirmed_points) < 2:\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == 13:  # Enter key to confirm the current point\n",
    "                confirm_point()\n",
    "            elif key == ord('q'):  # Press 'q' to quit\n",
    "                response = messagebox.askquestion(\"Exit\", \"Do you want to exit aligner?\")\n",
    "                if response == 'yes':\n",
    "                    print(\"Exiting point selection.\")\n",
    "                    cv2.destroyAllWindows()\n",
    "                    return video_dict\n",
    "            \n",
    "        # Save the confirmed points to the video dictionary\n",
    "        video_dict[video_path][\"align\"] = {\"first_point\": confirmed_points[0], \"second_point\": confirmed_points[1]}\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return video_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if messagebox.askyesno(\"Alignment\", \"Do you want to align the videos?\"):\n",
    "    video_dict = select_point_pairs(video_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_rectangle(x1, y1, x2, y2):\n",
    "    \"\"\"Define a rectangle based on two points.\n",
    "    \"\"\"\n",
    "    width = int(round(abs(x2 - x1)))\n",
    "    height = int(round(abs(y2 - y1)))\n",
    "    center = (int(round((x1+x2)//2)), int(round((y1+y2)//2))) # Round to integer\n",
    "    return center, width, height\n",
    "\n",
    "def draw_rectangle(image, center, width, height, angle = 0, color = (0, 255, 0), thickness = 2):\n",
    "    \"\"\"Draw a rectangle on an image.\n",
    "    \"\"\"\n",
    "    box = cv2.boxPoints(((center[0], center[1]), (width, height), angle))\n",
    "    box = np.intp(box)  # Convert to integer\n",
    "    cv2.drawContours(image, [box], 0, color, thickness)\n",
    "    cv2.circle(image, (int(round(center[0])), int(round(center[1]))), radius=2, color=color, thickness=-1)\n",
    "\n",
    "def select_cropping_region(video_dict):\n",
    "\n",
    "    video_files = list(video_dict.keys())\n",
    "\n",
    "    # Merge frames\n",
    "    image = merge_frames(video_files)\n",
    "    \n",
    "    # Get original dimensions and print them\n",
    "    width = image.shape[1]\n",
    "    height = image.shape[0]\n",
    "    print(f\"Original Size: {width}x{height}\")\n",
    "\n",
    "    # Initialize variables\n",
    "    clone = image.copy()\n",
    "    corners = []  # Current ROI \n",
    "    dragging = [False]  # For moving ROI\n",
    "    drag_start = None\n",
    "    angle = 0  # Current angle for rotation\n",
    "    rotate_factor = 1  # Amount of change per scroll\n",
    "    resize_factor = 2  # Amount of change per scroll\n",
    "    scale_factor = 1.0  # Scaling factor\n",
    "    square = False  # For enforcing a square shape\n",
    "\n",
    "    # Mouse callback function\n",
    "    def handle_mouse(event, x, y, flags, param):\n",
    "        nonlocal clone, corners, dragging,drag_start, angle, rotate_factor, resize_factor, square\n",
    "\n",
    "        # Adjust mouse coordinates according to scale factor\n",
    "        x = int(x / scale_factor)\n",
    "        y = int(y / scale_factor)\n",
    "\n",
    "        # Start drawing the rectangle\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            # angle = 0 # Reset angle\n",
    "            if not dragging[0]:\n",
    "                dragging[0] = True\n",
    "                corners = [(x, y)]  # Start new ROI at the clicked position\n",
    "\n",
    "        # Update rectangle during drawing\n",
    "        elif event == cv2.EVENT_MOUSEMOVE and dragging[0] and len(corners) == 1:\n",
    "            x1, y1 = corners[0]\n",
    "            x2, y2 = x, y # While dragging, update the end point\n",
    "\n",
    "            # If Ctrl is held, enforce a square shape\n",
    "            if flags & cv2.EVENT_FLAG_CTRLKEY:\n",
    "                side = max(abs(x2 - x1), abs(y2 - y1))\n",
    "                x2 = x1 + side if x2 > x1 else x1 - side\n",
    "                y2 = y1 + side if y2 > y1 else y1 - side\n",
    "                square = True\n",
    "            else:\n",
    "                square = False\n",
    "\n",
    "            center, width, height = define_rectangle(x1, y1, x2, y2)\n",
    "            clone = image.copy()\n",
    "            draw_rectangle(clone, center, width, height, angle, (0, 255, 255), 2)\n",
    "\n",
    "        # Finish drawing the rectangle\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            if dragging[0]:\n",
    "                dragging[0] = False\n",
    "                x1, y1 = corners[0]  # Start point\n",
    "                x2, y2 = x, y  # End point\n",
    "                if square:\n",
    "                    side = max(abs(x2 - x1), abs(y2 - y1))\n",
    "                    x2 = x1 + side if x2 > x1 else x1 - side\n",
    "                    y2 = y1 + side if y2 > y1 else y1 - side\n",
    "                corners.append((x2, y2))\n",
    "                \n",
    "        # Start moving the rectangle\n",
    "        elif event == cv2.EVENT_RBUTTONDOWN and len(corners) == 2:\n",
    "            dragging[0] = True\n",
    "            drag_start = (x, y)\n",
    "\n",
    "        # Move the rectangle\n",
    "        elif event == cv2.EVENT_MOUSEMOVE and dragging[0] and len(corners) == 2:\n",
    "            dx = x - drag_start[0]\n",
    "            dy = y - drag_start[1]\n",
    "            drag_start = (x, y)\n",
    "            x1, y1, x2, y2 = (corners[0][0] + dx, corners[0][1] + dy, corners[1][0] + dx, corners[1][1] + dy)\n",
    "            corners[0] = x1, y1\n",
    "            corners[1] = x2, y2\n",
    "            center, width, height = define_rectangle(x1, y1, x2, y2)\n",
    "            clone = image.copy()\n",
    "            draw_rectangle(clone, center, width, height, angle, (0, 255, 255), 2)\n",
    "\n",
    "        # Stop moving the rectangle\n",
    "        elif event == cv2.EVENT_RBUTTONUP and len(corners) == 2:\n",
    "            dragging[0] = False\n",
    "\n",
    "        # Resize or rotate the ROI using scroll wheel\n",
    "        elif event == cv2.EVENT_MOUSEWHEEL and len(corners) == 2:\n",
    "            x1, y1 = corners[0]\n",
    "            x2, y2 = corners[1]\n",
    "            if flags & cv2.EVENT_FLAG_CTRLKEY:  # Rotate with Ctrl key pressed\n",
    "                if flags > 0:  # Scroll up\n",
    "                    angle -= rotate_factor\n",
    "                else:  # Scroll down\n",
    "                    angle += rotate_factor\n",
    "            else:  # Resize without modifier key\n",
    "                width = max(abs(x2 - x1), 1)\n",
    "                height = max(abs(y2 - y1), 1)\n",
    "                ratio = width/height\n",
    "                if flags > 0:  # Scroll up\n",
    "                    x1 -= resize_factor*ratio\n",
    "                    y1 -= resize_factor\n",
    "                    x2 += resize_factor*ratio\n",
    "                    y2 += resize_factor\n",
    "                else:  # Scroll down\n",
    "                    x1 += resize_factor*ratio\n",
    "                    y1 += resize_factor\n",
    "                    x2 -= resize_factor*ratio\n",
    "                    y2 -= resize_factor\n",
    "                corners = [(x1, y1), (x2, y2)]\n",
    "            center, width, height = define_rectangle(x1, y1, x2, y2)\n",
    "            clone = image.copy()\n",
    "            draw_rectangle(clone, center, width, height, angle, (0, 255, 255), 2)\n",
    "\n",
    "        # Draw the updated ROI and display width, height, and angle\n",
    "        if len(corners) > 0:\n",
    "            x1, y1 = corners[0]\n",
    "            if len(corners) > 1:\n",
    "                x2, y2 = corners[1]\n",
    "            else:\n",
    "                x2, y2 = x, y\n",
    "                if square:\n",
    "                    side = max(abs(x2 - x1), abs(y2 - y1))\n",
    "                    x2 = x1 + side if x2 > x1 else x1 - side\n",
    "                    y2 = y1 + side if y2 > y1 else y1 - side\n",
    "            \n",
    "            # Display height, width, and angle at the bottom of the frame\n",
    "            center, width, height = define_rectangle(x1, y1, x2, y2)\n",
    "            text = f\"M: [{x}, {y}], C: {center}, W: {width}, H: {height}, A: {angle}\"  # Convert to int for display\n",
    "        else:\n",
    "            text = f\"M: [{x}, {y}]\"\n",
    "\n",
    "        font_scale, font_thickness = 0.5, 1\n",
    "        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)[0]\n",
    "        text_x, text_y = 10, clone.shape[0] - 10\n",
    "        cv2.rectangle(clone, (text_x - 5, text_y - text_size[1] - 5), \n",
    "                    (text_x + text_size[0] + 8, text_y + 5), (0, 0, 0), -1)  # Background for text\n",
    "        cv2.putText(clone, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    font_scale, (255, 255, 255), font_thickness)\n",
    "\n",
    "    # Set up the OpenCV window and bind the mouse callback\n",
    "    cv2.namedWindow(\"Select Region\")\n",
    "    cv2.setMouseCallback(\"Select Region\", handle_mouse)\n",
    "\n",
    "    while True:\n",
    "        display_image = cv2.resize(clone, None, fx=scale_factor, fy=scale_factor)\n",
    "        cv2.imshow(\"Select Region\", display_image)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord('+') and scale_factor < 2:\n",
    "            scale_factor += 0.1  # Zoom in\n",
    "        elif key == ord('-') and scale_factor > 0.5:\n",
    "            scale_factor -= 0.1  # Zoom out\n",
    "        elif key == ord('r'):\n",
    "            scale_factor = 1.0  # Reset zoom\n",
    "        \n",
    "\n",
    "        elif key == ord('c') and len(corners) == 2:  # Save the ROI\n",
    "            response = messagebox.askquestion(\"Crop\", \"Do you want to crop this region?\")\n",
    "            if response == 'yes':\n",
    "                break\n",
    "\n",
    "        elif key == ord('q'):  # Quit and save\n",
    "            response = messagebox.askquestion(\"Exit\", \"Do you want to exit the cropper?\")\n",
    "            if response == 'yes':\n",
    "                print(\"Cropping canceled.\")\n",
    "                cv2.destroyAllWindows()\n",
    "                return                \n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Ensure valid ROI\n",
    "    x1, y1 = corners[0]\n",
    "    x2, y2 = corners[1]\n",
    "    center, width, height = define_rectangle(x1, y1, x2, y2)\n",
    "\n",
    "    # Update all videos in the dictionary\n",
    "    for video_path in video_dict.keys():\n",
    "        video_dict[video_path][\"crop\"] = {\"center\": center, \"width\": width, \"height\": height, \"angle\": angle}\n",
    "\n",
    "    return video_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Size: 848x478\n"
     ]
    }
   ],
   "source": [
    "if messagebox.askyesno(\"Cropping\", \"Do you want to crop the videos?\"):\n",
    "    video_dict = select_cropping_region(video_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C:/Users/dhers/Desktop/Video_edit/VID-20250303-WA0002.mp4': {'trim': {'start': 0, 'end': 5}, 'crop': {'center': (404, 236), 'width': 505, 'height': 353, 'angle': 15}, 'align': None, 'resolution': {'width': 848, 'height': 478}, 'fps': 30}}\n"
     ]
    }
   ],
   "source": [
    "print(video_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video_dict(video_dict, file_path):\n",
    "    \"\"\"Save video_dict as a JSON file.\"\"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(video_dict, file)\n",
    "\n",
    "# Save video_dict to a file\n",
    "save_video_dict(video_dict, r'C:\\Users\\dhers\\Desktop\\Video_edit\\video_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_points(video_dict: dict, horizontal=False):\n",
    "    \"\"\"Calculate the mean alignment points from all videos in video_dict.\n",
    "\n",
    "    Args:\n",
    "        video_dict (dict): Dictionary containing video files and alignment points.\n",
    "        horizontal (bool): If True, force the points to have the same y-value.\n",
    "\n",
    "    Returns:\n",
    "        list: Mean alignment points [mean_point_1, mean_point_2].\n",
    "    \"\"\"\n",
    "    # Extract all alignment points\n",
    "    point_pairs = [\n",
    "        [video[\"align\"][\"first_point\"], video[\"align\"][\"second_point\"]]\n",
    "        for video in video_dict.values() if \"align\" in video\n",
    "    ]\n",
    "\n",
    "    if not point_pairs:\n",
    "        raise ValueError(\"No alignment points found in video_dict.\")\n",
    "\n",
    "    # Compute mean points\n",
    "    mean_points = np.mean(point_pairs, axis=0)\n",
    "    mean_point_1, mean_point_2 = mean_points.astype(int)\n",
    "\n",
    "    if horizontal:\n",
    "        # Calculate the mean y-value and align points horizontally\n",
    "        y_mean = (mean_point_1[1] + mean_point_2[1]) // 2\n",
    "        mean_point_1[1] = y_mean\n",
    "        mean_point_2[1] = y_mean\n",
    "\n",
    "    # Convert mean points to lists before returning\n",
    "    mean_points = [mean_point_1.tolist(), mean_point_2.tolist()]\n",
    "\n",
    "    print(f\"Mean points: {mean_points}\")\n",
    "    return mean_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformations(video_dict: dict, align=False, crop=False):\n",
    "    \"\"\"Apply trimming, alignment, cropping, resolution change, and FPS adjustment to videos.\"\"\"\n",
    "    \n",
    "    output_folder = os.path.join(os.path.dirname(next(iter(video_dict))), 'modified')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    if align:\n",
    "        horizontal = messagebox.askyesno(\"Alignment\", \"Do you want the points to stand on the same horizontal line?\")\n",
    "        mean_points = calculate_mean_points(video_dict, horizontal)\n",
    "\n",
    "        if mean_points is not None and len(mean_points) == 2:\n",
    "            mean_point_1, mean_point_2 = mean_points\n",
    "            mean_vector = np.array(mean_point_2) - np.array(mean_point_1)\n",
    "            mean_length = np.linalg.norm(mean_vector)\n",
    "            mean_angle = np.arctan2(mean_vector[1], mean_vector[0])\n",
    "    else:\n",
    "        mean_point_1 = mean_point_2 = mean_vector = mean_length = mean_angle = None  # No alignment\n",
    "\n",
    "    for video_path, video_data in video_dict.items():\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        # Set trimming parameters\n",
    "        trim = video_data.get(\"trim\", {})\n",
    "        start_frame = int(trim.get(\"start\", 0) * fps)\n",
    "        end_frame = int(trim.get(\"end\", total_frames / fps) * fps)\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "        # Set alignment parameters\n",
    "        if align and \"align\" in video_data:\n",
    "            point1, point2 = video_data[\"align\"][\"first_point\"], video_data[\"align\"][\"second_point\"]\n",
    "            vector = np.array(point2) - np.array(point1)\n",
    "            length = np.linalg.norm(vector)\n",
    "            angle = np.arctan2(vector[1], vector[0])\n",
    "\n",
    "            scale = mean_length / length if length != 0 else 1\n",
    "            rotation_angle = np.degrees(mean_angle + angle)\n",
    "            center = (width // 2, height // 2)\n",
    "            rotate_matrix = cv2.getRotationMatrix2D(center, rotation_angle, scale)\n",
    "\n",
    "            new_point1 = rotate_matrix[:, :2] @ np.array(point1).T + rotate_matrix[:, 2]\n",
    "            dx, dy = mean_point_1 - new_point1\n",
    "            translate_matrix = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "        else:\n",
    "            rotate_matrix, translate_matrix = None, None\n",
    "\n",
    "        # Set cropping parameters\n",
    "        crop_data = video_data.get(\"crop\", {})\n",
    "        crop_center = tuple(crop_data.get(\"center\", (width // 2, height // 2)))\n",
    "        crop_width = crop_data.get(\"width\", width)\n",
    "        crop_height = crop_data.get(\"height\", height)\n",
    "        crop_angle = crop_data.get(\"angle\", 0)\n",
    "\n",
    "        # Set resolution & FPS\n",
    "        output_width = crop_width # video_data.get(\"resolution\", {}).get(\"width\", width)\n",
    "        output_height = crop_height #video_data.get(\"resolution\", {}).get(\"height\", height)\n",
    "        output_fps = video_data.get(\"fps\", fps)\n",
    "\n",
    "        # Output video setup\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        video_name = os.path.basename(video_path)\n",
    "        output_path = os.path.join(output_folder, video_name)\n",
    "        out = cv2.VideoWriter(output_path, fourcc, output_fps, (output_width, output_height))\n",
    "\n",
    "        frame_count = start_frame\n",
    "        while cap.isOpened() and frame_count < end_frame:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Apply alignment\n",
    "            if rotate_matrix is not None and translate_matrix is not None:\n",
    "                frame = cv2.warpAffine(frame, rotate_matrix, (width, height))\n",
    "                frame = cv2.warpAffine(frame, translate_matrix, (width, height))\n",
    "\n",
    "            # Apply cropping\n",
    "            if crop:\n",
    "                M = cv2.getRotationMatrix2D(crop_center, crop_angle, 1)\n",
    "                frame = cv2.warpAffine(frame, M, (width, height))\n",
    "                x1 = int(crop_center[0] - crop_width / 2)\n",
    "                y1 = int(crop_center[1] - crop_height / 2)\n",
    "                x2 = int(crop_center[0] + crop_width / 2)\n",
    "                y2 = int(crop_center[1] + crop_height / 2)\n",
    "                frame = frame[y1:y2, x1:x2]\n",
    "\n",
    "            out.write(frame)\n",
    "            frame_count += 1\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        print(f\"Processed {video_name}. Trimmed {start_frame/fps:.2f}s - {end_frame/fps:.2f}s.\")\n",
    "\n",
    "    print(f\"Modified videos saved in '{output_folder}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video_dict(file_path):\n",
    "    \"\"\"Load video_dict from a JSON file.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "loaded_video_dict = load_video_dict(r'C:\\Users\\dhers\\Desktop\\Video_edit\\video_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed VID-20250303-WA0002.mp4. Trimmed 0.00s - 4.99s.\n",
      "Modified videos saved in 'C:/Users/dhers/Desktop/Video_edit\\modified'.\n"
     ]
    }
   ],
   "source": [
    "apply_transformations(loaded_video_dict, align = False, crop = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainstorm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
