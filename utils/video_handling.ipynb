{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAIN - Real & Artificial Intelligence for Neuroscience\n",
    "\n",
    "## Video handling\n",
    "\n",
    "Welcome to my video handling notebook!\n",
    "\n",
    "Here you'll find are a compilation of many functions I've written when working with videos.\n",
    "\n",
    "Since we record behavioral experiments, sometimes it is useful to cut, reshape, draw on, and add text to videos, among other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "from tkinter import Tk, filedialog, Label, Entry, Button, Toplevel, Spinbox, messagebox\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_video_files() -> list:\n",
    "    \"\"\"Select video files using a file dialog.\n",
    "\n",
    "    Returns:\n",
    "        list: List of selected video files.\n",
    "    \"\"\"\n",
    "    # Initialize Tkinter and hide the root window\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    \n",
    "    # Open file dialog to select video files\n",
    "    video_files = filedialog.askopenfilenames(\n",
    "        title=\"Select Video Files\",\n",
    "        filetypes=[(\"Video Files\", \"*.mp4 *.avi *.mkv *.mov\")]\n",
    "    )\n",
    "    if not video_files:\n",
    "        raise ValueError(\"No video files selected.\")\n",
    "    \n",
    "    print(f\"Selected {len(video_files)} videos.\")\n",
    "\n",
    "    return video_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Trimming and Resizing\n",
    "The most common video editing tasks are:\n",
    "- Trim the video if it is too long\n",
    "- Resize the video if it is too big (heavy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 videos.\n",
      "Processing: WIN_20240405_16_21_01_Pro_aligned.mp4, Start: 0s, End: 5s, 500x500, 30 FPS\n",
      "Processing: WIN_20240405_16_27_23_Pro_aligned.mp4, Start: 0s, End: 5s, 500x500, 30 FPS\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "def trim_video(file_path, width, height, fps, start_time=0, end_time=None):\n",
    "    \"\"\"\n",
    "    Changes the resolution of a video and trims it.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: Path to the input video file.\n",
    "    - width: Target width of the video.\n",
    "    - height: Target height of the video.\n",
    "    - start_time: Start time in seconds for the output video.\n",
    "    - end_time: End time in seconds for the output video (None for full length).\n",
    "    \"\"\"\n",
    "\n",
    "    folder_path = os.path.dirname(file_path)\n",
    "    output_folder = os.path.join(folder_path, \"trimmed\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_path = os.path.join(output_folder, os.path.basename(file_path))\n",
    "\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open {file_path}.\")\n",
    "        return\n",
    "        \n",
    "    # Get the original video properties\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    \n",
    "    # Convert time to frame numbers\n",
    "    start_frame = int(start_time * fps)\n",
    "    end_frame = int(end_time * fps) if end_time else total_frames\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_count = start_frame\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame_count >= end_frame:\n",
    "            break\n",
    "        \n",
    "        # Resize the frame\n",
    "        resized_frame = cv2.resize(frame, (width, height))\n",
    "\n",
    "        # Write the frame to the output video\n",
    "        out.write(resized_frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Processing: {os.path.basename(file_path)}, Start: {start_time}s, End: {end_time if end_time else 'end'}s, {width}x{height}, {fps} FPS\")\n",
    "\n",
    "def get_video_info(file_path):\n",
    "    \"\"\"Gets the resolution and FPS of a video file.\"\"\"\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open {file_path}.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    cap.release()\n",
    "    return width, height, fps\n",
    "\n",
    "class VideoTrimmer:\n",
    "    def __init__(self, root, video_files):\n",
    "        self.video_files = video_files\n",
    "        self.current_file = video_files[0] if video_files else None\n",
    "        \n",
    "        # Get video resolution and FPS\n",
    "        self.original_width, self.original_height, self.original_fps = get_video_info(self.current_file)\n",
    "        if self.original_width is None:\n",
    "            return\n",
    "        \n",
    "        self.aspect_ratio = self.original_height / self.original_width\n",
    "        \n",
    "        # Create a new window\n",
    "        self.window = Toplevel(root)\n",
    "        self.window.title(\"Video Editor\")\n",
    "        self.window.geometry(\"200x300\")\n",
    "\n",
    "        # Labels & Input Fields\n",
    "        Label(self.window, text=\"Start Time (mm:ss)\").pack()\n",
    "        self.start_time = Entry(self.window)\n",
    "        self.start_time.insert(0, \"00:00\")\n",
    "        self.start_time.pack()\n",
    "\n",
    "        Label(self.window, text=\"End Time (mm:ss)\").pack()\n",
    "        self.end_time = Entry(self.window)\n",
    "        self.end_time.insert(0, \"00:05\")\n",
    "        self.end_time.pack()\n",
    "\n",
    "        Label(self.window, text=f\"Resolution (default {self.original_width}x{self.original_height})\").pack()\n",
    "\n",
    "        self.width_spin = Spinbox(self.window, from_=100, to=4000, command=self.update_height)\n",
    "        self.width_spin.pack()\n",
    "        self.width_spin.delete(0, \"end\")\n",
    "        self.width_spin.insert(0, str(self.original_width))\n",
    "\n",
    "        self.height_spin = Spinbox(self.window, from_=100, to=4000, command=self.update_width)\n",
    "        self.height_spin.pack()\n",
    "        self.height_spin.delete(0, \"end\")\n",
    "        self.height_spin.insert(0, str(self.original_height))\n",
    "\n",
    "        Label(self.window, text=f\"FPS (default {self.original_fps})\").pack()\n",
    "        self.fps_spin = Spinbox(self.window, from_=1, to=200)\n",
    "        self.fps_spin.pack()\n",
    "        self.fps_spin.delete(0, \"end\")\n",
    "        self.fps_spin.insert(0, str(self.original_fps))\n",
    "\n",
    "        Button(self.window, text=\"Run\", command=self.run).pack()\n",
    "\n",
    "    def update_height(self):\n",
    "        \"\"\"Automatically adjust height based on width to maintain aspect ratio.\"\"\"\n",
    "        try:\n",
    "            width = int(self.width_spin.get())\n",
    "            height = int(width * self.aspect_ratio)\n",
    "            self.height_spin.delete(0, \"end\")\n",
    "            self.height_spin.insert(0, str(height))\n",
    "        except ValueError:\n",
    "            pass  # Ignore invalid input\n",
    "\n",
    "    def update_width(self):\n",
    "        \"\"\"Automatically adjust width based on height to maintain aspect ratio.\"\"\"\n",
    "        try:\n",
    "            height = int(self.height_spin.get())\n",
    "            width = int(height / self.aspect_ratio)\n",
    "            self.width_spin.delete(0, \"end\")\n",
    "            self.width_spin.insert(0, str(width))\n",
    "        except ValueError:\n",
    "            pass  # Ignore invalid input\n",
    "\n",
    "    def run(self):\n",
    "        start_time = self.convert_time(self.start_time.get())\n",
    "        end_time = self.convert_time(self.end_time.get())\n",
    "        width = int(self.width_spin.get())  \n",
    "        height = int(self.height_spin.get())  \n",
    "        fps = int(self.fps_spin.get())  \n",
    "\n",
    "        for file in self.video_files:\n",
    "            trim_video(file, width, height, fps, start_time, end_time)\n",
    "        \n",
    "        print(\"Processing complete.\")\n",
    "        self.window.destroy()\n",
    "        self.window.quit()  # Ensures mainloop exits completely\n",
    "\n",
    "    def convert_time(self, time_str):\n",
    "        \"\"\"Convert mm:ss format to seconds.\"\"\"\n",
    "        minutes, seconds = map(int, time_str.split(\":\"))\n",
    "        return minutes * 60 + seconds\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        root = Tk()\n",
    "        root.withdraw()  # Hide the main window\n",
    "        \n",
    "        video_files = select_video_files()\n",
    "        \n",
    "        if not video_files:  # If the user cancels, exit without error\n",
    "            print(\"Operation canceled.\")\n",
    "            root.destroy()\n",
    "            sys.exit(0)  \n",
    "        \n",
    "        VideoTrimmer(root, video_files)\n",
    "        root.mainloop()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nOperation interrupted by user.\")\n",
    "        root.destroy()\n",
    "        sys.exit(0)  # Exit without error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Aligning\n",
    "When we record videos with different cameras, or our camera moves a bit between recordings, we can use the following function to align the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_frames_within_video(video_file, num_frames: int = 5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Merge a specified number of random frames from each video file into a single image.\n",
    "\n",
    "    Args:\n",
    "        num_frames (int): Number of random frames to merge from each video. Default is 5.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Merged image.\n",
    "    \"\"\"\n",
    "    merged_image = None\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    selected_frame_indices = random.sample(range(total_frames), num_frames)\n",
    "\n",
    "    for frame_idx in selected_frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if not success:\n",
    "            print(f\"Could not read frame {frame_idx} from {video_file}\")\n",
    "            continue\n",
    "\n",
    "        # Calculate transparency\n",
    "        transparency = round(1 / num_frames, 4)\n",
    "        transparent_frame = (frame * transparency).astype(np.uint8)\n",
    "        \n",
    "        if merged_image is None:\n",
    "            # Initialize merged image\n",
    "            merged_image = np.zeros_like(transparent_frame)\n",
    "        \n",
    "        # Add transparent frame to the merged image\n",
    "        merged_image = cv2.add(merged_image, transparent_frame)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    return merged_image\n",
    "\n",
    "def align_videos():\n",
    "\n",
    "    print(\"Instructions:\")\n",
    "    print(\"1. Left-click to select points.\")\n",
    "    print(\"2. Enter to confirm the current point.\")\n",
    "    print(\"3. Select two points on each video to align them.\")\n",
    "    print(\"Press 'q' to quit without aligning.\")\n",
    "\n",
    "    # Initialize Tkinter and hide the root window\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    \n",
    "    # Open file dialog to select video files\n",
    "    video_files = select_video_files()\n",
    "\n",
    "    # Initialize variables\n",
    "    zoom_scale = 5  # How much to zoom in\n",
    "    zoom_window_size = 25  # Half the width/height of the zoomed-in area\n",
    "    point_pairs = []  # To store pairs of points for each video\n",
    "    first_frames = []\n",
    "\n",
    "    # Define callback function for point selection\n",
    "    def select_points(event, x, y, flags, param):\n",
    "        nonlocal frame, temp_frame, current_point, confirmed_points, zoom_scale, zoom_window_size\n",
    "\n",
    "        #if event == cv2.EVENT_MOUSEMOVE:   \n",
    "\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            # Update the current point with the clicked position\n",
    "            current_point = (x, y)\n",
    "            # Draw the current point\n",
    "            cv2.circle(temp_frame, current_point, 3, (0, 255, 0), -1)\n",
    "            # Draw the confirmed points on the frame\n",
    "            for point in confirmed_points: \n",
    "                cv2.circle(temp_frame, point, 3, (0, 0, 255), -1)\n",
    "            # Display the frame\n",
    "            cv2.imshow('Select Points', temp_frame)\n",
    "        \n",
    "        # Create zoomed-in display\n",
    "        x1 = max(0, x - zoom_window_size)\n",
    "        x2 = min(temp_frame.shape[1], x + zoom_window_size)\n",
    "        y1 = max(0, y - zoom_window_size)\n",
    "        y2 = min(temp_frame.shape[0], y + zoom_window_size)\n",
    "\n",
    "        zoomed_area = temp_frame[y1:y2, x1:x2]\n",
    "        \n",
    "        # Resize zoomed-in area\n",
    "        zoomed_area_resized = cv2.resize(zoomed_area, None, fx=zoom_scale, fy=zoom_scale, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # Add crosshair to the center\n",
    "        center_x = zoomed_area_resized.shape[1] // 2\n",
    "        center_y = zoomed_area_resized.shape[0] // 2\n",
    "        color = (0, 255, 0)  # Black crosshair\n",
    "        thickness = 2\n",
    "        line_length = 20  # Length of crosshair lines\n",
    "\n",
    "        # Draw vertical line\n",
    "        cv2.line(zoomed_area_resized, (center_x, center_y - line_length), (center_x, center_y + line_length), color, thickness)\n",
    "        # Draw horizontal line\n",
    "        cv2.line(zoomed_area_resized, (center_x - line_length, center_y), (center_x + line_length, center_y), color, thickness)\n",
    "\n",
    "        if x2 > (temp_frame.shape[1] - zoomed_area_resized.shape[1] - 10) and y1 < (10 + zoomed_area_resized.shape[0]):\n",
    "            # Overlay zoomed-in area in the top-left corner of the frame\n",
    "            overlay_x1 = 10\n",
    "            overlay_x2 = 10 + zoomed_area_resized.shape[1]\n",
    "            overlay_y1 = 10\n",
    "            overlay_y2 = 10 + zoomed_area_resized.shape[0]\n",
    "        \n",
    "        else:\n",
    "            # Overlay zoomed-in area in the top-right corner of the frame\n",
    "            overlay_x1 = temp_frame.shape[1] - zoomed_area_resized.shape[1] - 10\n",
    "            overlay_x2 = temp_frame.shape[1] - 10\n",
    "            overlay_y1 = 10\n",
    "            overlay_y2 = 10 + zoomed_area_resized.shape[0]\n",
    "        \n",
    "        # Reset the frame\n",
    "        temp_frame = frame.copy()\n",
    "\n",
    "        # Draw the current point\n",
    "        if current_point is not None:\n",
    "            cv2.circle(temp_frame, current_point, 3, (0, 255, 0), -1)\n",
    "        # Draw the confirmed points on the frame\n",
    "        for point in confirmed_points:\n",
    "            cv2.circle(temp_frame, point, 3, (0, 0, 255), -1)\n",
    "        # Display the zoomed-in area\n",
    "        temp_frame[overlay_y1:overlay_y2, overlay_x1:overlay_x2] = zoomed_area_resized\n",
    "        # Display the frame\n",
    "        cv2.imshow('Select Points', temp_frame)\n",
    "\n",
    "    def confirm_point():\n",
    "        \"\"\"Confirm the current point and add it to the list.\"\"\"\n",
    "        nonlocal temp_frame, confirmed_points, current_point\n",
    "        if current_point is not None:\n",
    "            confirmed_points.append(current_point)\n",
    "            # Draw the confirmed points on the frame\n",
    "            for point in confirmed_points: \n",
    "                cv2.circle(temp_frame, point, 3, (0, 0, 255), -1)\n",
    "            # Display the frame\n",
    "            cv2.imshow('Select Points', temp_frame)\n",
    "            current_point = None\n",
    "            print(f\"Point confirmed: {confirmed_points[-1]}\")  # Feedback to the user\n",
    "    \n",
    "    # Step 1: Extract first frames and collect two points for each video\n",
    "    for video_path in video_files:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame = merge_frames_within_video(video_path)\n",
    "        first_frames.append((frame, video_path))\n",
    "        confirmed_points = []  # Store the two confirmed points for this video\n",
    "        current_point = None  # Temporary point being adjusted\n",
    "        temp_frame = frame.copy()  # Create a copy of the frame\n",
    "\n",
    "        # Run the mouse callback with the frame and confirmed points\n",
    "        cv2.imshow('Select Points', frame)\n",
    "        cv2.setMouseCallback('Select Points', select_points)\n",
    "\n",
    "        # Wait for user to confirm two points\n",
    "        while len(confirmed_points) < 2:\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == 13:  # Enter key to confirm the current point\n",
    "                confirm_point()\n",
    "            elif key == ord('q'):  # Press 'q' to quit\n",
    "                response = messagebox.askquestion(\"Exit\", \"Do you want to exit aligner?\")\n",
    "                if response == 'yes':\n",
    "                    print(\"Exiting point selection.\")\n",
    "                    cv2.destroyAllWindows()\n",
    "                    return\n",
    "            \n",
    "        # Save the confirmed points\n",
    "        point_pairs.append(confirmed_points)\n",
    "        cap.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Step 2: Calculate mean points\n",
    "    if not point_pairs:\n",
    "        print(\"No points were selected.\")\n",
    "        return\n",
    "    \n",
    "    mean_points = np.mean(point_pairs, axis=0)\n",
    "    mean_point1, mean_point2 = mean_points.astype(int)\n",
    "\n",
    "    response = messagebox.askquestion(\"Alignment\", \"Do you want the points to stand on the same horizontal line?\")  \n",
    "    if response == 'yes':\n",
    "        # Calculate the mean y-value\n",
    "        y_mean = (mean_point1[1] + mean_point2[1]) // 2  # Use integer division if you want the result as int\n",
    "\n",
    "        # Update the y-values of both points\n",
    "        mean_point1[1] = y_mean\n",
    "        mean_point2[1] = y_mean\n",
    "    \n",
    "    print(f\"Mean points: {mean_point1}, {mean_point2}\")\n",
    "    \n",
    "    # Step 3: Align videos (rotate, resize, then translate)\n",
    "    output_folder = os.path.join(os.path.dirname(video_files[0]), 'aligned')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    mean_vector = mean_point2 - mean_point1\n",
    "    mean_length = np.linalg.norm(mean_vector)\n",
    "    mean_angle = np.arctan2(mean_vector[1], mean_vector[0])\n",
    "    \n",
    "    for (frame, video_path), points in zip(first_frames, point_pairs):\n",
    "        point1, point2 = points\n",
    "        vector = np.array(point2) - np.array(point1)\n",
    "        angle = np.arctan2(vector[1], vector[0])\n",
    "        length = np.linalg.norm(vector)\n",
    "        \n",
    "        scale = mean_length / length\n",
    "        rotation_angle = mean_angle + angle\n",
    "\n",
    "        # Step 3.1: Rotate and resize\n",
    "        height, width = frame.shape[:2]\n",
    "        center = (width // 2, height // 2)\n",
    "        M_rotate_scale = cv2.getRotationMatrix2D(center, np.degrees(rotation_angle), scale)\n",
    "        rotated_resized_frame = cv2.warpAffine(frame, M_rotate_scale, (width, height))\n",
    "        \n",
    "        # Step 3.2: Translate\n",
    "        new_point1 = np.dot(M_rotate_scale[:, :2], np.array(point1).T) + M_rotate_scale[:, 2]\n",
    "        dx, dy = mean_point1[0] - new_point1[0], mean_point1[1] - new_point1[1]\n",
    "        M_translate = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "        aligned_frame = cv2.warpAffine(rotated_resized_frame, M_translate, frame.shape[1::-1])\n",
    "        \n",
    "        # Save aligned video\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        video_name = os.path.basename(video_path)\n",
    "        output_path = os.path.join(output_folder, video_name)\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Apply the same transformations to each frame\n",
    "            rotated_resized_frame = cv2.warpAffine(frame, M_rotate_scale, frame.shape[1::-1])\n",
    "            aligned_frame = cv2.warpAffine(rotated_resized_frame, M_translate, frame.shape[1::-1])\n",
    "            out.write(aligned_frame)\n",
    "        \n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "        print(f\"Aligned '{video_name}' with scale {scale:.2f}, rotation {rotation_angle:.2f}, and translation {dx:.2f}, {dy:.2f}.\")\n",
    "    \n",
    "    print(f\"Aligned videos saved in '{output_folder}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructions:\n",
      "1. Left-click to select points.\n",
      "2. Enter to confirm the current point.\n",
      "3. Select two points on each video to align them.\n",
      "Press 'q' to quit without aligning.\n",
      "Selected 2 videos.\n",
      "Point confirmed: (44, 250)\n",
      "Point confirmed: (454, 250)\n",
      "Point confirmed: (45, 249)\n",
      "Point confirmed: (453, 248)\n",
      "Mean points: [ 44 249], [453 249]\n",
      "Aligned 'WIN_20240405_16_21_01_Pro_aligned.mp4' with scale 1.00, rotation 0.00, and translation -0.50, -1.00.\n",
      "Aligned 'WIN_20240405_16_27_23_Pro_aligned.mp4' with scale 1.00, rotation -0.00, and translation -0.50, 0.51.\n",
      "Aligned videos saved in 'C:/Users/dhers/OneDrive/Doctorado/Experimentos/3xTg_B2/2024_04-E+M/4_cropped/trimmed\\Aligned'.\n"
     ]
    }
   ],
   "source": [
    "align_videos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Cropping\n",
    "The following function will let you crop the video to the desired size.\n",
    "- It's useful for when you have unused space in the video, or if you record multiple animals simultaneously with one camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_frames_across_videos(video_files: list) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Merge the first frame of each video file into a single image.\n",
    "\n",
    "    Args:\n",
    "        video_files (list): List of video files.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Merged image.\n",
    "    \"\"\"\n",
    "    merged_image = None\n",
    "    \n",
    "    for video_file in video_files:\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "        success, frame = cap.read()\n",
    "        cap.release()\n",
    "        \n",
    "        if not success:\n",
    "            print(f\"Could not read first frame of {video_file}\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate transparency\n",
    "        transparency = round(1 / len(video_files), 4)\n",
    "        transparent_frame = (frame * transparency).astype(np.uint8)\n",
    "        \n",
    "        if merged_image is None:\n",
    "            # Initialize merged image\n",
    "            merged_image = np.zeros_like(transparent_frame)\n",
    "        \n",
    "        # Add transparent frame to the merged image\n",
    "        merged_image = cv2.add(merged_image, transparent_frame)\n",
    "    \n",
    "    return merged_image\n",
    "\n",
    "def define_rectangle(x1, y1, x2, y2):\n",
    "    \"\"\"Define a rectangle based on two points.\n",
    "    \"\"\"\n",
    "    width = int(round(abs(x2 - x1)))\n",
    "    height = int(round(abs(y2 - y1)))\n",
    "    center = [int(round((x1+x2)//2)), int(round((y1+y2)//2))] # Round to integer\n",
    "    return center, width, height\n",
    "\n",
    "def draw_rectangle(image, center, width, height, angle = 0, color = (0, 255, 0), thickness = 2):\n",
    "    \"\"\"Draw a rectangle on an image.\n",
    "    \"\"\"\n",
    "    box = cv2.boxPoints(((center[0], center[1]), (width, height), angle))\n",
    "    box = np.intp(box)  # Convert to integer\n",
    "    cv2.drawContours(image, [box], 0, color, thickness)\n",
    "    cv2.circle(image, (int(round(center[0])), int(round(center[1]))), radius=2, color=color, thickness=-1)\n",
    "\n",
    "def crop_video(file_path, center, width, height, angle = 0):\n",
    "    \"\"\"Crop a video to a specific size and center.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the video file.\n",
    "        center (tuple): Center of the cropped region.\n",
    "        width (int): Width of the cropped region.\n",
    "        height (int): Height of the cropped region.\n",
    "        angle (int, optional): Angle of rotation. Defaults to 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    folder_path = os.path.dirname(file_path)\n",
    "    output_folder = os.path.join(folder_path, \"cropped\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_path = os.path.join(output_folder, os.path.basename(file_path))\n",
    "    \n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open {file_path}.\")\n",
    "        return\n",
    "        \n",
    "    # Output video writer with the cropped size\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if angle != 0:\n",
    "            # Rotate the entire frame\n",
    "            rotation_matrix = cv2.getRotationMatrix2D(tuple(center), angle, 1.0)\n",
    "            frame = cv2.warpAffine(frame, rotation_matrix, (frame.shape[1], frame.shape[0]))\n",
    "        \n",
    "        # Crop the rotated region\n",
    "        frame = frame[\n",
    "            center[1] - height // 2:center[1] + height // 2,\n",
    "            center[0] - width // 2:center[0] + width // 2,\n",
    "        ]\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Cropped {os.path.basename(output_path)} with size {width}x{height}.\")\n",
    "\n",
    "def cropper():\n",
    "    \"\"\"\n",
    "    Crop multiple videos to a specific size and center.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get video files\n",
    "    video_files = select_video_files()\n",
    "\n",
    "    # Merge frames\n",
    "    image = merge_frames_across_videos(video_files)\n",
    "    \n",
    "    # Get original dimensions and print them\n",
    "    width = image.shape[1]\n",
    "    height = image.shape[0]\n",
    "    print(f\"Original Size: {width}x{height}\")\n",
    "\n",
    "    # Initialize variables\n",
    "    clone = image.copy()\n",
    "    corners = []  # Current ROI \n",
    "    dragging = [False]  # For moving ROI\n",
    "    drag_start = None\n",
    "    angle = 0  # Current angle for rotation\n",
    "    rotate_factor = 1  # Amount of change per scroll\n",
    "    resize_factor = 2  # Amount of change per scroll\n",
    "    scale_factor = 1.0  # Scaling factor\n",
    "    square = False  # For enforcing a square shape\n",
    "\n",
    "    # Mouse callback function\n",
    "    def handle_mouse(event, x, y, flags, param):\n",
    "        nonlocal clone, corners, dragging,drag_start, angle, rotate_factor, resize_factor, square\n",
    "\n",
    "        # Adjust mouse coordinates according to scale factor\n",
    "        x = int(x / scale_factor)\n",
    "        y = int(y / scale_factor)\n",
    "\n",
    "        # Start drawing the rectangle\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            # angle = 0 # Reset angle\n",
    "            if not dragging[0]:\n",
    "                dragging[0] = True\n",
    "                corners = [(x, y)]  # Start new ROI at the clicked position\n",
    "\n",
    "        # Update rectangle during drawing\n",
    "        elif event == cv2.EVENT_MOUSEMOVE and dragging[0] and len(corners) == 1:\n",
    "            x1, y1 = corners[0]\n",
    "            x2, y2 = x, y # While dragging, update the end point\n",
    "\n",
    "            # If Ctrl is held, enforce a square shape\n",
    "            if flags & cv2.EVENT_FLAG_CTRLKEY:\n",
    "                side = max(abs(x2 - x1), abs(y2 - y1))\n",
    "                x2 = x1 + side if x2 > x1 else x1 - side\n",
    "                y2 = y1 + side if y2 > y1 else y1 - side\n",
    "                square = True\n",
    "            else:\n",
    "                square = False\n",
    "\n",
    "            center, width, height = define_rectangle(x1, y1, x2, y2)\n",
    "            clone = image.copy()\n",
    "            draw_rectangle(clone, center, width, height, angle, (0, 255, 255), 2)\n",
    "\n",
    "        # Finish drawing the rectangle\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            if dragging[0]:\n",
    "                dragging[0] = False\n",
    "                x1, y1 = corners[0]  # Start point\n",
    "                x2, y2 = x, y  # End point\n",
    "                if square:\n",
    "                    side = max(abs(x2 - x1), abs(y2 - y1))\n",
    "                    x2 = x1 + side if x2 > x1 else x1 - side\n",
    "                    y2 = y1 + side if y2 > y1 else y1 - side\n",
    "                corners.append((x2, y2))\n",
    "                \n",
    "        # Start moving the rectangle\n",
    "        elif event == cv2.EVENT_RBUTTONDOWN and len(corners) == 2:\n",
    "            dragging[0] = True\n",
    "            drag_start = (x, y)\n",
    "\n",
    "        # Move the rectangle\n",
    "        elif event == cv2.EVENT_MOUSEMOVE and dragging[0] and len(corners) == 2:\n",
    "            dx = x - drag_start[0]\n",
    "            dy = y - drag_start[1]\n",
    "            drag_start = (x, y)\n",
    "            x1, y1, x2, y2 = (corners[0][0] + dx, corners[0][1] + dy, corners[1][0] + dx, corners[1][1] + dy)\n",
    "            corners[0] = x1, y1\n",
    "            corners[1] = x2, y2\n",
    "            center, width, height = define_rectangle(x1, y1, x2, y2)\n",
    "            clone = image.copy()\n",
    "            draw_rectangle(clone, center, width, height, angle, (0, 255, 255), 2)\n",
    "\n",
    "        # Stop moving the rectangle\n",
    "        elif event == cv2.EVENT_RBUTTONUP and len(corners) == 2:\n",
    "            dragging[0] = False\n",
    "\n",
    "        # Resize or rotate the ROI using scroll wheel\n",
    "        elif event == cv2.EVENT_MOUSEWHEEL and len(corners) == 2:\n",
    "            x1, y1 = corners[0]\n",
    "            x2, y2 = corners[1]\n",
    "            if flags & cv2.EVENT_FLAG_CTRLKEY:  # Rotate with Ctrl key pressed\n",
    "                if flags > 0:  # Scroll up\n",
    "                    angle -= rotate_factor\n",
    "                else:  # Scroll down\n",
    "                    angle += rotate_factor\n",
    "            else:  # Resize without modifier key\n",
    "                width = max(abs(x2 - x1), 1)\n",
    "                height = max(abs(y2 - y1), 1)\n",
    "                ratio = width/height\n",
    "                if flags > 0:  # Scroll up\n",
    "                    x1 -= resize_factor*ratio\n",
    "                    y1 -= resize_factor\n",
    "                    x2 += resize_factor*ratio\n",
    "                    y2 += resize_factor\n",
    "                else:  # Scroll down\n",
    "                    x1 += resize_factor*ratio\n",
    "                    y1 += resize_factor\n",
    "                    x2 -= resize_factor*ratio\n",
    "                    y2 -= resize_factor\n",
    "                corners = [(x1, y1), (x2, y2)]\n",
    "            center, width, height = define_rectangle(x1, y1, x2, y2)\n",
    "            clone = image.copy()\n",
    "            draw_rectangle(clone, center, width, height, angle, (0, 255, 255), 2)\n",
    "\n",
    "        # Draw the updated ROI and display width, height, and angle\n",
    "        if len(corners) > 0:\n",
    "            x1, y1 = corners[0]\n",
    "            if len(corners) > 1:\n",
    "                x2, y2 = corners[1]\n",
    "            else:\n",
    "                x2, y2 = x, y\n",
    "                if square:\n",
    "                    side = max(abs(x2 - x1), abs(y2 - y1))\n",
    "                    x2 = x1 + side if x2 > x1 else x1 - side\n",
    "                    y2 = y1 + side if y2 > y1 else y1 - side\n",
    "            \n",
    "            # Display height, width, and angle at the bottom of the frame\n",
    "            center, width, height = define_rectangle(x1, y1, x2, y2)\n",
    "            text = f\"M: [{x}, {y}], C: {center}, W: {width}, H: {height}, A: {angle}\"  # Convert to int for display\n",
    "        else:\n",
    "            text = f\"M: [{x}, {y}]\"\n",
    "\n",
    "        font_scale, font_thickness = 0.5, 1\n",
    "        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)[0]\n",
    "        text_x, text_y = 10, clone.shape[0] - 10\n",
    "        cv2.rectangle(clone, (text_x - 5, text_y - text_size[1] - 5), \n",
    "                    (text_x + text_size[0] + 8, text_y + 5), (0, 0, 0), -1)  # Background for text\n",
    "        cv2.putText(clone, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    font_scale, (255, 255, 255), font_thickness)\n",
    "\n",
    "    # Set up the OpenCV window and bind the mouse callback\n",
    "    cv2.namedWindow(\"Select Region\")\n",
    "    cv2.setMouseCallback(\"Select Region\", handle_mouse)\n",
    "\n",
    "    while True:\n",
    "        display_image = cv2.resize(clone, None, fx=scale_factor, fy=scale_factor)\n",
    "        cv2.imshow(\"Select Region\", display_image)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord('+') and scale_factor < 2:\n",
    "            scale_factor += 0.1  # Zoom in\n",
    "        elif key == ord('-') and scale_factor > 0.5:\n",
    "            scale_factor -= 0.1  # Zoom out\n",
    "        elif key == ord('r'):\n",
    "            scale_factor = 1.0  # Reset zoom\n",
    "        \n",
    "\n",
    "        elif key == ord('c') and len(corners) == 2:  # Save the ROI\n",
    "            response = messagebox.askquestion(\"Crop\", \"Do you want to crop this region?\")\n",
    "            if response == 'yes':\n",
    "                break\n",
    "\n",
    "        elif key == ord('q'):  # Quit and save\n",
    "            response = messagebox.askquestion(\"Exit\", \"Do you want to exit the cropper?\")\n",
    "            if response == 'yes':\n",
    "                print(\"Cropping canceled.\")\n",
    "                cv2.destroyAllWindows()\n",
    "                return                \n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Ensure valid ROI\n",
    "    x1, y1 = corners[0]\n",
    "    x2, y2 = corners[1]\n",
    "    center, width, height = define_rectangle(x1, y1, x2, y2)\n",
    "\n",
    "    # Apply cropping\n",
    "    for file in video_files:\n",
    "        crop_video(file, center, width, height, angle)\n",
    "\n",
    "    print(f\"Videos cropped and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 36 videos.\n",
      "Original Size: 1080x960\n",
      "Cropped 2024_04-R01_C1i-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R01_C1i-Splash.mp4 with size 960x800.\n",
      "Cropped 2024_04-R02_C1d-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R02_C1d-Splash.mp4 with size 960x800.\n",
      "Cropped 2024_04-R03_C1a-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R03_C1a-Splash.mp4 with size 960x800.\n",
      "Cropped 2024_04-R04_C2i-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R04_C2i-Splash.mp4 with size 960x800.\n",
      "Cropped 2024_04-R05_C2d-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R05_C2d-Splash.mp4 with size 960x800.\n",
      "Cropped 2024_04-R06_C2a-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R06_C2a-Splash.mp4 with size 960x800.\n",
      "Cropped 2024_04-R07_C3i-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R07_C3i-Splash.mp4 with size 960x800.\n",
      "Cropped 2024_04-R08_C3d-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R08_C3d-Splash.mp4 with size 960x800.\n",
      "Cropped 2024_04-R09_C3n-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R09_C3n-Splash.mp4 with size 960x800.\n",
      "Cropped 2024_04-R10_C4i-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R10_C4i-Splash.mp4 with size 960x800.\n",
      "Cropped 2024_04-R11_C4d-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R11_C4d-Splash.mp4 with size 960x800.\n",
      "Cropped 2024_04-R12_C5i-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R12_C5i-Splash.mp4 with size 960x800.\n",
      "Cropped 2024_04-R13_C5d-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R13_C5d-Splash.mp4 with size 960x800.\n",
      "Cropped 2024_04-R14_C5a-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R14_C5a-Splash.mp4 with size 960x800.\n",
      "Cropped 2024_04-R15_C5n-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R15_C5n-Splash.mp4 with size 960x800.\n",
      "Cropped 2024_04-R16_C6i-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R16_C6i-Splash.mp4 with size 960x800.\n",
      "Cropped 2024_04-R17_C6d-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R17_C6d-Splash.mp4 with size 960x800.\n",
      "Cropped 2024_04-R18_C6a-OF.mp4 with size 960x800.\n",
      "Cropped 2024_04-R18_C6a-Splash.mp4 with size 960x800.\n",
      "Videos cropped and saved\n"
     ]
    }
   ],
   "source": [
    "cropper()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainstorm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
