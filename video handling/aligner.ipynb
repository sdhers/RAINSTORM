{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAIN - Real & Artificial Intelligence in Neuroscience\n",
    "\n",
    "## Video aligner\n",
    "\n",
    "How to use:\n",
    "- Click 'Run all'\n",
    "- Select the videos you want to align\n",
    "- On each frame, click on two points that you want to be aligned between videos\n",
    "- The aligned videos will be stored in the 'Aligned' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tkinter import Tk, filedialog, messagebox\n",
    "\n",
    "def align_videos():\n",
    "\n",
    "    print(\"Instructions:\")\n",
    "    print(\"1. Left-click to select points.\")\n",
    "    print(\"2. Enter to confirm the current point.\")\n",
    "    print(\"3. Select two points on each video to align them.\")\n",
    "    print(\"Press 'q' to quit without aligning.\")\n",
    "\n",
    "    # Initialize Tkinter and hide the root window\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    \n",
    "    # Open file dialog to select video files\n",
    "    video_files = filedialog.askopenfilenames(\n",
    "        title=\"Select Video Files\",\n",
    "        filetypes=[(\"Video Files\", \"*.mp4 *.avi *.mkv *.mov\")]\n",
    "    )\n",
    "    if not video_files:\n",
    "        raise ValueError(\"No video files selected.\")\n",
    "    \n",
    "    print(f\"Selected {len(video_files)} videos.\")\n",
    "\n",
    "    # Initialize variables\n",
    "    zoom_scale = 5  # How much to zoom in\n",
    "    zoom_window_size = 25  # Half the width/height of the zoomed-in area\n",
    "    point_pairs = []  # To store pairs of points for each video\n",
    "    first_frames = []\n",
    "\n",
    "    # Define callback function for point selection\n",
    "    def select_points(event, x, y, flags, param):\n",
    "        nonlocal frame, temp_frame, current_point, confirmed_points, zoom_scale, zoom_window_size\n",
    "\n",
    "        #if event == cv2.EVENT_MOUSEMOVE:   \n",
    "\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            # Update the current point with the clicked position\n",
    "            current_point = (x, y)\n",
    "            # Draw the current point\n",
    "            cv2.circle(temp_frame, current_point, 3, (0, 255, 0), -1)\n",
    "            # Draw the confirmed points on the frame\n",
    "            for point in confirmed_points: \n",
    "                cv2.circle(temp_frame, point, 3, (0, 0, 255), -1)\n",
    "            # Display the frame\n",
    "            cv2.imshow('Select Points', temp_frame)\n",
    "        \n",
    "        # Create zoomed-in display\n",
    "        x1 = max(0, x - zoom_window_size)\n",
    "        x2 = min(temp_frame.shape[1], x + zoom_window_size)\n",
    "        y1 = max(0, y - zoom_window_size)\n",
    "        y2 = min(temp_frame.shape[0], y + zoom_window_size)\n",
    "\n",
    "        zoomed_area = temp_frame[y1:y2, x1:x2]\n",
    "        \n",
    "        # Resize zoomed-in area\n",
    "        zoomed_area_resized = cv2.resize(zoomed_area, None, fx=zoom_scale, fy=zoom_scale, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # Add crosshair to the center\n",
    "        center_x = zoomed_area_resized.shape[1] // 2\n",
    "        center_y = zoomed_area_resized.shape[0] // 2\n",
    "        color = (0, 255, 0)  # Black crosshair\n",
    "        thickness = 2\n",
    "        line_length = 20  # Length of crosshair lines\n",
    "\n",
    "        # Draw vertical line\n",
    "        cv2.line(zoomed_area_resized, (center_x, center_y - line_length), (center_x, center_y + line_length), color, thickness)\n",
    "        # Draw horizontal line\n",
    "        cv2.line(zoomed_area_resized, (center_x - line_length, center_y), (center_x + line_length, center_y), color, thickness)\n",
    "\n",
    "        if x2 > (temp_frame.shape[1] - zoomed_area_resized.shape[1] - 10) and y1 < (10 + zoomed_area_resized.shape[0]):\n",
    "            # Overlay zoomed-in area in the top-left corner of the frame\n",
    "            overlay_x1 = 10\n",
    "            overlay_x2 = 10 + zoomed_area_resized.shape[1]\n",
    "            overlay_y1 = 10\n",
    "            overlay_y2 = 10 + zoomed_area_resized.shape[0]\n",
    "        \n",
    "        else:\n",
    "            # Overlay zoomed-in area in the top-right corner of the frame\n",
    "            overlay_x1 = temp_frame.shape[1] - zoomed_area_resized.shape[1] - 10\n",
    "            overlay_x2 = temp_frame.shape[1] - 10\n",
    "            overlay_y1 = 10\n",
    "            overlay_y2 = 10 + zoomed_area_resized.shape[0]\n",
    "        \n",
    "        # Reset the frame\n",
    "        temp_frame = frame.copy()\n",
    "\n",
    "        # Draw the current point\n",
    "        if current_point is not None:\n",
    "            cv2.circle(temp_frame, current_point, 3, (0, 255, 0), -1)\n",
    "        # Draw the confirmed points on the frame\n",
    "        for point in confirmed_points:\n",
    "            cv2.circle(temp_frame, point, 3, (0, 0, 255), -1)\n",
    "        # Display the zoomed-in area\n",
    "        temp_frame[overlay_y1:overlay_y2, overlay_x1:overlay_x2] = zoomed_area_resized\n",
    "        # Display the frame\n",
    "        cv2.imshow('Select Points', temp_frame)\n",
    "\n",
    "    def confirm_point():\n",
    "        \"\"\"Confirm the current point and add it to the list.\"\"\"\n",
    "        nonlocal temp_frame, confirmed_points, current_point\n",
    "        if current_point is not None:\n",
    "            confirmed_points.append(current_point)\n",
    "            # Draw the confirmed points on the frame\n",
    "            for point in confirmed_points: \n",
    "                cv2.circle(temp_frame, point, 3, (0, 0, 255), -1)\n",
    "            # Display the frame\n",
    "            cv2.imshow('Select Points', temp_frame)\n",
    "            current_point = None\n",
    "            print(f\"Point confirmed: {confirmed_points[-1]}\")  # Feedback to the user\n",
    "    \n",
    "    # Step 1: Extract first frames and collect two points for each video\n",
    "    for video_path in video_files:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            first_frames.append((frame, video_path))\n",
    "            confirmed_points = []  # Store the two confirmed points for this video\n",
    "            current_point = None  # Temporary point being adjusted\n",
    "            temp_frame = frame.copy()  # Create a copy of the frame\n",
    "\n",
    "            # Run the mouse callback with the frame and confirmed points\n",
    "            cv2.imshow('Select Points', frame)\n",
    "            cv2.setMouseCallback('Select Points', select_points)\n",
    "\n",
    "            # Wait for user to confirm two points\n",
    "            while len(confirmed_points) < 2:\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == 13:  # Enter key to confirm the current point\n",
    "                    confirm_point()\n",
    "                elif key == ord('q'):  # Press 'q' to quit\n",
    "                    response = messagebox.askquestion(\"Exit\", \"Do you want to exit aligner?\")\n",
    "                    if response == 'yes':\n",
    "                        print(\"Exiting point selection.\")\n",
    "                        cv2.destroyAllWindows()\n",
    "                        return\n",
    "                \n",
    "            # Save the confirmed points\n",
    "            point_pairs.append(confirmed_points)\n",
    "        cap.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Step 2: Calculate mean points\n",
    "    if not point_pairs:\n",
    "        print(\"No points were selected.\")\n",
    "        return\n",
    "    \n",
    "    mean_points = np.mean(point_pairs, axis=0)\n",
    "    mean_point1, mean_point2 = mean_points.astype(int)\n",
    "\n",
    "    response = messagebox.askquestion(\"Alignment\", \"Do you want the points to stand on the same horizontal line?\")  \n",
    "    if response == 'yes':\n",
    "        # Calculate the mean y-value\n",
    "        y_mean = (mean_point1[1] + mean_point2[1]) // 2  # Use integer division if you want the result as int\n",
    "\n",
    "        # Update the y-values of both points\n",
    "        mean_point1[1] = y_mean\n",
    "        mean_point2[1] = y_mean\n",
    "    \n",
    "    print(f\"Mean points: {mean_point1}, {mean_point2}\")\n",
    "    \n",
    "    # Step 3: Align videos (rotate, resize, then translate)\n",
    "    output_folder = os.path.join(os.path.dirname(video_files[0]), 'Aligned')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    mean_vector = mean_point2 - mean_point1\n",
    "    mean_length = np.linalg.norm(mean_vector)\n",
    "    mean_angle = np.arctan2(mean_vector[1], mean_vector[0])\n",
    "    \n",
    "    for (frame, video_path), points in zip(first_frames, point_pairs):\n",
    "        point1, point2 = points\n",
    "        vector = np.array(point2) - np.array(point1)\n",
    "        angle = np.arctan2(vector[1], vector[0])\n",
    "        length = np.linalg.norm(vector)\n",
    "        \n",
    "        scale = mean_length / length\n",
    "        rotation_angle = mean_angle + angle\n",
    "\n",
    "        # Step 3.1: Rotate and resize\n",
    "        height, width = frame.shape[:2]\n",
    "        center = (width // 2, height // 2)\n",
    "        M_rotate_scale = cv2.getRotationMatrix2D(center, np.degrees(rotation_angle), scale)\n",
    "        rotated_resized_frame = cv2.warpAffine(frame, M_rotate_scale, (width, height))\n",
    "        \n",
    "        # Step 3.2: Translate\n",
    "        new_point1 = np.dot(M_rotate_scale[:, :2], np.array(point1).T) + M_rotate_scale[:, 2]\n",
    "        dx, dy = mean_point1[0] - new_point1[0], mean_point1[1] - new_point1[1]\n",
    "        M_translate = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "        aligned_frame = cv2.warpAffine(rotated_resized_frame, M_translate, frame.shape[1::-1])\n",
    "        \n",
    "        # Save aligned video\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        video_name = os.path.basename(video_path)\n",
    "        output_path = os.path.join(output_folder, video_name.replace('.', '_aligned.'))\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Apply the same transformations to each frame\n",
    "            rotated_resized_frame = cv2.warpAffine(frame, M_rotate_scale, frame.shape[1::-1])\n",
    "            aligned_frame = cv2.warpAffine(rotated_resized_frame, M_translate, frame.shape[1::-1])\n",
    "            out.write(aligned_frame)\n",
    "        \n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "        print(f\"Aligned '{video_name}' with scale {scale:.2f}, rotation {rotation_angle:.2f}, and translation {dx:.2f}, {dy:.2f}.\")\n",
    "    \n",
    "    print(f\"Aligned videos saved in '{output_folder}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructions:\n",
      "1. Left-click to select points.\n",
      "2. Enter to confirm the current point.\n",
      "3. Select two points on each video to align them.\n",
      "Press 'q' to quit without aligning.\n",
      "Selected 2 videos.\n",
      "Point confirmed: (161, 315)\n",
      "Point confirmed: (622, 165)\n",
      "Point confirmed: (103, 320)\n",
      "Point confirmed: (616, 326)\n",
      "Mean points: [132 281], [619 281]\n",
      "Aligned 'VID-20250124-WA0010.mp4' with scale 1.00, rotation -0.31, and translation -17.14, 51.15.\n",
      "Aligned 'VID-20250124-WA0011.mp4' with scale 0.95, rotation 0.01, and translation 11.79, -38.45.\n",
      "Aligned videos saved in 'C:/Users/dhers/Desktop/prueba\\Aligned'.\n"
     ]
    }
   ],
   "source": [
    "align_videos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainstorm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
